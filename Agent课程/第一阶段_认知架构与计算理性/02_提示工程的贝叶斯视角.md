# ç¬¬02è¯¾ï¼šæç¤ºå·¥ç¨‹çš„è´å¶æ–¯è§†è§’

**å…³é”®è¯**ï¼šBayesian, ICL (In-Context Learning), éšå¼æ¢¯åº¦ä¸‹é™, Label Space, Input Space

---

## ç¬”è®°åŒºåŸŸ

ä½ å¥½ã€‚è¿™æ˜¯ã€ŠAI Agent æ·±åº¦æ¶æ„ä¸æ•°å­¦åŸç†ã€‹çš„ç¬¬äºŒè¯¾ã€‚

åœ¨ä¸ŠèŠ‚è¯¾ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº† System 2 çš„å®è§‚æ¶æ„ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ˜¾å¾®é•œå¯¹å‡† Agent ä¸ LLM äº¤äº’çš„æœ€åŸºç¡€æ¥å£â€”â€”**Prompt**ã€‚

ä½œä¸ºç ”ä¸‰å­¦ç”Ÿï¼Œä½ åº”è¯¥æœ‰è¿‡è¿™ç§å›°æƒ‘ï¼šä¸ºä»€ä¹ˆæ”¹å˜ Prompt ä¸­çš„ä¸€ä¸ªè¯ï¼Œæˆ–è€…æ”¹å˜ Few-shot ç¤ºä¾‹çš„é¡ºåºï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šå‰§çƒˆæ³¢åŠ¨ï¼Ÿå¦‚æœä¸ç†è§£å…¶èƒŒåçš„æ•°å­¦åŸç†ï¼ŒPrompt Engineering å°±æ°¸è¿œæ˜¯â€œç‚¼ä¸¹â€å’Œâ€œç„å­¦â€ã€‚

æœ¬èŠ‚è¯¾æˆ‘ä»¬å°†ä»**æ¦‚ç‡å›¾æ¨¡å‹ï¼ˆProbabilistic Graphical Modelsï¼‰**å’Œ**è´å¶æ–¯æ¨æ–­**çš„è§†è§’ï¼Œé€šè¿‡ä¸¥è°¨çš„æ•°å­¦å®šä¹‰æ¥è§£æ„ In-Context Learning (ICL)ã€‚

---

# ğŸ§  ç¬¬02è¯¾ï¼šæç¤ºå·¥ç¨‹çš„è´å¶æ–¯è§†è§’ (The Bayesian Perspective of Prompting)

### 0. èƒŒæ™¯é©±åŠ¨ï¼šä»â€œç‚¼ä¸¹â€åˆ°â€œæ¨æ–­â€

* **æŒ‘æˆ˜ (Challenge)**ï¼š
  LLM å¯¹ Prompt çš„æ ¼å¼ã€ç¤ºä¾‹é¡ºåºï¼ˆOrderingï¼‰ã€ç¤ºä¾‹æ ‡ç­¾åˆ†å¸ƒï¼ˆLabel Distributionï¼‰æå…¶æ•æ„Ÿã€‚ä¾‹å¦‚ï¼ŒGPT-3 åœ¨æŸäº›ä»»åŠ¡ä¸Šï¼Œä»…æ”¹å˜ç¤ºä¾‹é¡ºåºï¼Œå‡†ç¡®ç‡æ³¢åŠ¨å¯è¾¾ 50% ä»¥ä¸Šã€‚è¿™ç§**ä¸ç¨³å®šæ€§**æ˜¯æ„å»ºé²æ£’ Agent çš„æœ€å¤§éšœç¢ã€‚
* **æ ¸å¿ƒé—®é¢˜**ï¼š
  æˆ‘ä»¬é€šå¸¸å°† LLM è§†ä¸ºå‡½æ•° $f(x)$ï¼Œè¯•å›¾é€šè¿‡è°ƒæ•´è¾“å…¥ $x$ æ¥æ‹Ÿåˆè¾“å‡ºã€‚ä½†å®é™…ä¸Šï¼Œé¢„è®­ç»ƒæ¨¡å‹æ˜¯ä¸€ä¸ªå·¨å¤§çš„**è”åˆæ¦‚ç‡åˆ†å¸ƒ**ã€‚ICL çš„è¿‡ç¨‹å¹¶ä¸æ˜¯â€œæ¢¯åº¦ä¸‹é™å­¦ä¹ â€ï¼Œè€Œæ˜¯**åœ¨éšç©ºé—´ä¸­çš„å®šä½**ã€‚
* **çªç ´ç‚¹ (Breakthrough)**ï¼š
  **Xie et al. (2022)** å’Œ **Min et al. (2022)** ç­‰ç ”ç©¶æå‡ºï¼ŒICL æœ¬è´¨ä¸Šæ˜¯**éšå¼è´å¶æ–¯æ¨æ–­ï¼ˆImplicit Bayesian Inferenceï¼‰**ã€‚
* **æ”¹è¿›æ–¹å‘**ï¼š
  ä¸å†ç›²ç›®å°è¯• Promptï¼Œè€Œæ˜¯é€šè¿‡**è¯æ®æœ€å¤§åŒ–ï¼ˆEvidence Maximizationï¼‰**å’Œ**åéªŒæ ¡å‡†ï¼ˆPosterior Calibrationï¼‰**æ¥è®¾è®¡ Prompt ç³»ç»Ÿã€‚

---

### 1. ç†è®ºæ ¸å¿ƒï¼šéšæ½œå˜é‡ä¸åéªŒæ¦‚ç‡

#### 1.1 æ•°å­¦å®šä¹‰ï¼šæ½œåœ¨æ¦‚å¿µæ¨¡å‹ (Latent Concept Model)

åœ¨è´å¶æ–¯è§†è§’ä¸‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹ä¸ä»…ä»…å­¦ä¹ äº† $P(\text{next token})$ï¼Œè€Œæ˜¯å­¦ä¹ äº†æµ·é‡çš„**æ½œåœ¨æ¦‚å¿µï¼ˆLatent Conceptsï¼‰**ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªæ½œåœ¨å˜é‡è®°ä¸º $\theta$ã€‚

å½“æˆ‘ä»¬åœ¨ Prompt ä¸­æä¾›ç¤ºä¾‹ï¼ˆDemonstrationsï¼‰ $D = \{(x_1, y_1), ..., (x_k, y_k)\}$ æ—¶ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®¡ç®—é¢„æµ‹åˆ†å¸ƒ $P(y|x, D)$ã€‚æ ¹æ®å…¨æ¦‚ç‡å…¬å¼ï¼Œè¿™å¯ä»¥åˆ†è§£ä¸ºï¼š

$$
P(y|x, D) = \int_{\Theta} \underbrace{P(y|x, \theta)}_{\text{Execution}} \cdot \underbrace{P(\theta|D, x)}_{\text{Locating}} \, d\theta
$$

è¿™é‡ŒåŒ…å«ä¸¤ä¸ªå…³é”®è¿‡ç¨‹ï¼š

1. **$P(\theta|D, x)$ - ä»»åŠ¡å®šä½ (Task Location)**ï¼š
   è¿™æ˜¯ Prompt çš„æ ¸å¿ƒä½œç”¨ã€‚Prompt $D$ ä¸æ˜¯ä¸ºäº†è®©æ¨¡å‹å­¦ä¹  $x \to y$ çš„æ˜ å°„ï¼ˆæ¨¡å‹ä¸éœ€è¦è¿™å‡ ä¸ªæ ·æœ¬æ¥å­¦ä¹ è¯­æ³•æˆ–é€»è¾‘ï¼‰ï¼Œè€Œæ˜¯ä¸ºäº†**ç¼©å‡æ½œåœ¨æ¦‚å¿µ $\theta$ çš„ä¸ç¡®å®šæ€§**ï¼ˆé™ä½ç†µï¼‰ã€‚
   * $D$ å°±åƒæ˜¯ä¸€ä¸ªæœç´¢æŸ¥è¯¢ï¼Œåœ¨æ¨¡å‹çš„å‚æ•°ç©ºé—´ä¸­æ£€ç´¢å‡ºæœ€åŒ¹é…çš„ $\theta$ï¼ˆä¾‹å¦‚ï¼šâ€œæƒ…æ„Ÿåˆ†æâ€ä»»åŠ¡æˆ–â€œä»£ç ç¿»è¯‘â€ä»»åŠ¡ï¼‰ã€‚
2. **$P(y|x, \theta)$ - ä»»åŠ¡æ‰§è¡Œ (Task Execution)**ï¼š
   ä¸€æ—¦ $\theta$ è¢«ç¡®å®šï¼ˆåéªŒåˆ†å¸ƒå¡Œç¼©ä¸ºå°–å³°ï¼‰ï¼Œæ¨¡å‹åˆ©ç”¨é¢„è®­ç»ƒçš„çŸ¥è¯†åœ¨ $\theta$ çš„æŒ‡å¯¼ä¸‹å¤„ç† $x$ã€‚

#### 1.2 ä¸ºä»€ä¹ˆéšæœºæ ‡ç­¾ä¹Ÿæœ‰æ•ˆï¼Ÿ

**Min et al. (2022)** åœ¨è®ºæ–‡ *Rethinking the Role of Demonstrations* ä¸­å‘ç°ä¸€ä¸ªåç›´è§‰ç°è±¡ï¼š**å³ä½¿å°† Few-shot ç¤ºä¾‹ä¸­çš„æ ‡ç­¾ $y_i$ éšæœºæ‰“ä¹±ï¼ˆå³æä¾›é”™è¯¯çš„ç¤ºä¾‹ï¼‰ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¸‹é™ä¹Ÿéå¸¸å¾®å¼±ã€‚**

**è´å¶æ–¯è§£é‡Š**ï¼š
Prompt $D$ çš„ä¸»è¦è´¡çŒ®åœ¨äº $P(x_{demo})$ å’Œ $Format(D)$ï¼Œå®ƒä»¬æå¤§åœ°å¸®åŠ©æ¨¡å‹å®šä½äº†**è¾“å…¥åˆ†å¸ƒ**å’Œ**è¾“å‡ºæ ¼å¼**ï¼ˆå³ $\theta$ çš„å¤§è‡´åŒºåŸŸï¼‰ã€‚è€Œ $x \to y$ çš„å…·ä½“æ˜ å°„å…³ç³»ï¼Œæ¨¡å‹æ—©å·²åœ¨é¢„è®­ç»ƒä¸­ä¹ å¾—ï¼Œä¸éœ€è¦ä¾èµ–è¿™å‡ ä¸ª Few-shot æ¥å­¦ä¹ ã€‚
è¿™è¯æ˜äº† ICL ä¸»è¦æ˜¯**ä»»åŠ¡è¯†åˆ«ï¼ˆTask Recognitionï¼‰**è€Œéä»»åŠ¡å­¦ä¹ ã€‚

---

### 2. æ¶æ„è§£å‰–ï¼šåŸºäºè´å¶æ–¯çš„ Prompt ä¼˜åŒ–æµæ°´çº¿

åœ¨å·¥ç¨‹è½åœ°ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸Šè¿°ç†è®ºæ„å»ºä¸€ä¸ª**æ£€ç´¢-æ„å»º-æ ¡å‡†**çš„é—­ç¯ç³»ç»Ÿã€‚

#### 2.1 ç³»ç»Ÿè®¾è®¡å›¾ (Mermaid)

```mermaid
graph TD
    UserIn[ç”¨æˆ·è¾“å…¥ Query x] --> Retriever
    DB[(å‘é‡æ•°æ®åº“ VectorDB)] --> Retriever
  
    subgraph Bayesian Prompting Pipeline
        %% ä¿®æ”¹ç‚¹ï¼šç»™ label å†…å®¹åŠ ä¸ŠåŒå¼•å· "..."
        Retriever -->|Top-K ç›¸ä¼¼æ ·æœ¬| Demo["è¯æ® D: {(xi, yi)}"]
        Demo --> Construct[Prompt æ„å»ºå™¨]
        UserIn --> Construct
      
        Construct -->|Raw Prompt| LLM((Frozen LLM))
      
        LLM -->|Raw Logits| Dist["åˆ†å¸ƒ P(y|x, D)"]
      
        subgraph Calibration Layer
            Bias["å…ˆéªŒåç½® P(y|N/A, D)"]
            Dist --> CalibCalc{æ ¡å‡†è®¡ç®—}
            Bias --> CalibCalc
        end
    end
  
    CalibCalc -->|Calibrated Prob| Output[æœ€ç»ˆè¾“å‡º y]
  
    style Calibration Layer fill:#e1f5fe,stroke:#333,stroke-dasharray: 5 5
```

#### 2.2 å…³é”®æ­¥éª¤è§£æ

1. **è¯æ®æ£€ç´¢ (Evidence Retrieval)**ï¼š
   * ä¸ºäº†æœ€å¤§åŒ– $P(\theta|D)$ï¼Œæˆ‘ä»¬éœ€è¦ $D$ ä¸ $x$ å°½å¯èƒ½ç›¸å…³ã€‚ä½¿ç”¨ KNN ä»è®­ç»ƒåº“ä¸­æ£€ç´¢ Top-K æ ·æœ¬ä½œä¸º Few-shotï¼Œè¿™æ¯”éšæœºé‡‡æ ·èƒ½æ˜¾è‘—æå‡åéªŒæ¦‚ç‡çš„å‡†ç¡®æ€§ã€‚
2. **å…ˆéªŒåç½®è®¡ç®— (Prior Bias Calculation)**ï¼š
   * æ¨¡å‹å¾€å¾€å­˜åœ¨ **Majority Label Bias**ï¼ˆå€¾å‘è®­ç»ƒé›†å¸¸è§è¯ï¼‰å’Œ **Recency Bias**ï¼ˆå€¾å‘ Prompt æœ«å°¾è¯ï¼‰ã€‚
   * æˆ‘ä»¬éœ€è¦è®¡ç®— $P(y|\text{"N/A"}, D)$ï¼Œå³ç»™æ¨¡å‹ä¸€ä¸ªç©ºè¾“å…¥ "N/A"ï¼Œçœ‹å®ƒåœ¨ä»…æœ‰ Prompt $D$ çš„æƒ…å†µä¸‹å€¾å‘äºè¾“å‡ºä»€ä¹ˆã€‚
3. **æ ¡å‡† (Calibration)**ï¼š
   * åˆ©ç”¨ä»¿å°„å˜æ¢æˆ– PMIï¼ˆäº’ä¿¡æ¯ï¼‰æ–¹æ³•ï¼Œä»åŸå§‹ Logits ä¸­å‡å»å…ˆéªŒåç½®ã€‚

---

### 3. Code & Engineeringï¼šå®ç° Contextual Calibration

æˆ‘ä»¬å°†å®ç° **Zhao et al. (2021)** æå‡ºçš„ **"Calibrate Before Use"** ç®—æ³•ã€‚è¿™æ˜¯ Prompt Engineering é¢†åŸŸå°†æ•°å­¦åŸç†è½¬åŒ–ä¸ºå·¥ç¨‹ä»£ç çš„å…¸èŒƒã€‚

**æ ¸å¿ƒé€»è¾‘**ï¼š
ä¿®æ­£åçš„åˆ†æ•° $Score(y) \propto P(y|x, D) / P(y|\text{"N/A"}, D)$ã€‚
åœ¨å¯¹æ•°ç©ºé—´ä¸­ï¼š$\log \tilde{P}(y) = \log P(y|x, D) - \log P(y|\text{"N/A"}, D)$ã€‚

```python
import torch
import torch.nn.functional as F
from transformers import AutoModelForCausalLM, AutoTokenizer

class BayesianCalibrator:
    def __init__(self, model_name="gpt2"):
        # åœ¨å®é™… Agent ä¸­ï¼Œé€šå¸¸ä½¿ç”¨ llama3-8b æˆ– mistral
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)
        self.model.eval()

    def get_logits(self, prompt: str):
        """è·å–æ¨¡å‹è¾“å‡ºçš„åŸå§‹ Logits"""
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        with torch.no_grad():
            outputs = self.model(**inputs)
        # å–æœ€åä¸€ä¸ª token çš„ logitsï¼Œä»£è¡¨å¯¹ä¸‹ä¸€ä¸ªè¯çš„é¢„æµ‹
        return outputs.logits[0, -1, :]

    def calibrate_inference(self, few_shot_prompt: str, user_query: str, candidate_labels: list):
        """
        è¾“å…¥:
            few_shot_prompt: åŒ…å«ç¤ºä¾‹çš„ Prompt æ¨¡æ¿
            user_query: å½“å‰ç”¨æˆ·é—®é¢˜
            candidate_labels: å€™é€‰æ ‡ç­¾åˆ—è¡¨ (e.g., ["Positive", "Negative"])
        è¾“å‡º:
            æ ¡å‡†åçš„æ ‡ç­¾åŠå…¶æ¦‚ç‡
        """
        # 1. è·å–å€™é€‰æ ‡ç­¾çš„ Token ID
        label_ids = [self.tokenizer.encode(l)[0] for l in candidate_labels] # ç®€åŒ–å‡è®¾æ ‡ç­¾ä¸ºå•token
      
        # 2. è®¡ç®— Contextual Prior (Bias) - è¾“å…¥ä¸º "N/A"
        # è¿™ä¸€æ­¥è®¡ç®— P(y | N/A, D)ï¼Œå³æ¨¡å‹çš„å›ºæœ‰åè§
        content_free_input = "N/A" 
        prior_prompt = f"{few_shot_prompt}\nInput: {content_free_input}\nOutput:"
        prior_logits = self.get_logits(prior_prompt)
        prior_scores = prior_logits[label_ids]
      
        # 3. è®¡ç®— True Posterior - è¾“å…¥ä¸º user_query
        # è¿™ä¸€æ­¥è®¡ç®— P(y | x, D)
        actual_prompt = f"{few_shot_prompt}\nInput: {user_query}\nOutput:"
        posterior_logits = self.get_logits(actual_prompt)
        posterior_scores = posterior_logits[label_ids]
      
        # 4. æ‰§è¡Œæ ¡å‡† (Calibration)
        # WçŸ©é˜µåœ¨è¿™é‡Œç®€åŒ–ä¸ºå•ä½çŸ©é˜µï¼Œé‡‡ç”¨å‡æ³•ï¼ˆå¯¹æ•°é™¤æ³•ï¼‰æ¶ˆé™¤åç½®
        # Calibrated Score = Posterior - Prior
        calibrated_scores = posterior_scores - prior_scores
      
        # 5. å½’ä¸€åŒ–ä¸ºæ¦‚ç‡
        probs = F.softmax(calibrated_scores, dim=0)
      
        # æ ¼å¼åŒ–è¾“å‡º
        result = {label: prob.item() for label, prob in zip(candidate_labels, probs)}
        best_label = candidate_labels[torch.argmax(probs).item()]
      
        return best_label, result

# --- Engineering Mockup ---
# åœ¨å®é™…å·¥ç¨‹ä¸­ï¼ŒPrompt æ¨¡æ¿é€šå¸¸ç”± Retriever åŠ¨æ€æ„å»º
prompt_template = """
Input: The movie was amazing.
Output: Positive
Input: I waste my time.
Output: Negative
"""

# calibrator = BayesianCalibrator()
# label, probs = calibrator.calibrate_inference(prompt_template, "It's okay I guess.", ["Positive", "Negative"])
# print(f"Prediction: {label}, Probability: {probs}")
```

---

### 4. Paper Drivenï¼šæ ¸å¿ƒè®ºæ–‡ä¸è´¡çŒ®

1. **Xie, S. M., et al. (2022). *An Explanation of In-Context Learning as Implicit Bayesian Inference*. (ICLR 2022)**
   * **è´¡çŒ®**ï¼šå»ºç«‹äº† ICL çš„ç†è®ºæ¡†æ¶ã€‚è¯æ˜äº†å½“é¢„è®­ç»ƒæ•°æ®åˆ†å¸ƒå¯ä»¥è¢«å»ºæ¨¡ä¸ºéšé©¬å°”å¯å¤«æ¨¡å‹ï¼ˆHMMï¼‰çš„æ··åˆæ—¶ï¼ŒICL è¿‡ç¨‹åœ¨æ•°å­¦ä¸Šç­‰ä»·äºæ¨æ–­ HMM çš„æ½œåœ¨æ¦‚å¿µã€‚
2. **Min, S., et al. (2022). *Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?*. (EMNLP 2022)**
   * **è´¡çŒ®**ï¼šé€šè¿‡å¤§é‡æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰è¯æ˜ï¼šè¾“å…¥åˆ†å¸ƒ $P(x)$ å’Œæ ‡ç­¾ç©ºé—´ $P(y)$ è¿œæ¯”è¾“å…¥-æ ‡ç­¾æ˜ å°„ $P(y|x)$ é‡è¦ã€‚è¿™ä¸º Prompt Engineering æä¾›äº†â€œå½¢å¼é‡äºå†…å®¹â€çš„æŒ‡å¯¼åŸåˆ™ã€‚
3. **Zhao, T., et al. (2021). *Calibrate Before Use: Improving Few-Shot Performance of Language Models*. (ICML 2021)**
   * **è´¡çŒ®**ï¼šå‘ç°äº† LLM çš„ Logits å­˜åœ¨ä¸¥é‡çš„åå·®ï¼Œå¹¶æå‡ºäº† Contextual Calibrationï¼ˆå³ä¸Šè¿°ä»£ç å®ç°çš„æ–¹æ³•ï¼‰ï¼Œåœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡å‹çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº† Few-shot æ€§èƒ½ã€‚

---

### 5. Critical Thinkingï¼šæ‰¹åˆ¤æ€§åˆ†æ

* **Context Window ç“¶é¢ˆ**ï¼š
  è´å¶æ–¯ç†è®ºæš—ç¤ºè¯æ® $D$ è¶Šå¤šï¼ŒåéªŒè¶Šå‡†ã€‚ä½† Context Window æ˜¯æœ‰é™çš„ï¼Œä¸” Transformer çš„ Attention å¼€é”€æ˜¯ $O(L^2)$ã€‚

  * *SOTA æ–¹æ¡ˆ*ï¼š**LLMLingua** (EMNLP 2023) åˆ©ç”¨å°æ¨¡å‹è®¡ç®— Token çš„å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ï¼Œå‹ç¼© Prompt ä¸­çš„ä½ä¿¡æ¯é‡ Tokenï¼Œä»è€Œåœ¨æœ‰é™çª—å£å†…å¡å…¥æ›´å¤š Evidenceã€‚
* **Prompt æœç´¢çš„ç®—åŠ›æˆæœ¬**ï¼š
  æ‰‹åŠ¨å¯»æ‰¾æœ€ä½³ Prompt ç±»ä¼¼äºåœ¨ç¦»æ•£ç©ºé—´è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œæ•ˆç‡æä½ã€‚

  * *è§£å†³æ€è·¯*ï¼š**DSPy (Stanford)** æˆ– **APE (Automatic Prompt Engineer)**ã€‚å°† Prompt è§†ä¸ºå¯ä¼˜åŒ–çš„å‚æ•°ï¼Œåˆ©ç”¨ LLM æœ¬èº«ä½œä¸ºä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œè¯„ä¼°æ¥è‡ªåŠ¨æœç´¢æœ€ä½³ Promptã€‚
* **Latent Variable çš„å¤šå³°æ€§**ï¼š
  å¦‚æœ Prompt ä¸­çš„ç¤ºä¾‹ç”±å¤šä¸ªä¸åŒä»»åŠ¡æ··åˆè€Œæˆï¼ˆä¾‹å¦‚æ—¢æœ‰ç¿»è¯‘åˆæœ‰æ‘˜è¦ï¼‰ï¼ŒåéªŒåˆ†å¸ƒ $P(\theta|D)$ å¯èƒ½ä¼šå‡ºç°å¤šå³°ï¼ˆMulti-modalï¼‰ï¼Œå¯¼è‡´æ¨¡å‹å›°æƒ‘ã€‚

  * *å·¥ç¨‹çº¦æŸ*ï¼šåŠ¡å¿…ä¿æŒ Retriever æ£€ç´¢å‡ºçš„ç¤ºä¾‹åœ¨è¯­ä¹‰å’Œæ ¼å¼ä¸Šçš„**ä¸€è‡´æ€§ï¼ˆConsistencyï¼‰**ã€‚

---

### 6. å‰æ²¿æ‰©å±•

* **Active Prompting**:
  å€Ÿé‰´ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰ã€‚Agent é¦–å…ˆå°è¯•è§£å†³é—®é¢˜ï¼Œè®¡ç®—è¾“å‡ºçš„ä¸ç¡®å®šæ€§ï¼ˆUncertaintyï¼Œä¾‹å¦‚ Entropyï¼‰ã€‚å¯¹äºé«˜ä¸ç¡®å®šæ€§çš„é—®é¢˜ï¼ŒAgent ä¸»åŠ¨è¯·æ±‚äººç±»æ ‡æ³¨ï¼Œå¹¶å°†è¯¥æ ·æœ¬åŠ å…¥ Prompt $D$ã€‚è¿™æ˜¯ä¸€ç§**äººåœ¨å›è·¯ï¼ˆHuman-in-the-loopï¼‰çš„è´å¶æ–¯ä¼˜åŒ–**ã€‚
* **Prompt as Program**:
  éšç€ CoT çš„å‘å±•ï¼ŒPrompt ä¸å†åªæ˜¯æ–‡æœ¬ï¼Œè€Œæ˜¯åŒ…å«é€»è¾‘æ§åˆ¶æµï¼ˆIf-Elseï¼‰ã€‚è´å¶æ–¯è§†è§’æ‰©å±•ä¸º**æ¦‚ç‡ç¼–ç¨‹ï¼ˆProbabilistic Programmingï¼‰**ï¼ŒAgent çš„æ‰§è¡Œè¿‡ç¨‹å˜æˆäº†åœ¨æ¦‚ç‡å›¾ä¸Šçš„é‡‡æ ·è¿‡ç¨‹ã€‚

---

**æ€»ç»“**ï¼š
Prompt Engineering ä¸æ˜¯ç„å­¦ï¼Œå®ƒæ˜¯**åœ¨é¢„è®­ç»ƒå‚æ•°å®šä¹‰çš„æµå½¢ä¸Šè¿›è¡Œè´å¶æ–¯å®šä½**ã€‚
åœ¨å·¥ç¨‹å®ç°ä¸­ï¼Œä¸è¦åªå…³æ³¨ Prompt å†™å¾—â€œå¥½ä¸å¥½çœ‹â€ï¼Œé€šè¿‡ **Retriever ä¼˜åŒ–è¯æ®è´¨é‡**ï¼Œé€šè¿‡ **Calibrator ä¿®æ­£å…ˆéªŒåç½®**ï¼Œæ‰æ˜¯æ„å»º Robust Agent çš„æ­£é“ã€‚

ä¸‹ä¸€è¯¾ï¼Œæˆ‘ä»¬å°†æ·±å…¥ Agent çš„â€œæ€ç»´é“¾æ¡â€ï¼Œæ¢è®¨ **ReAct èŒƒå¼ä¸æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰çš„åº•å±‚æœºåˆ¶**ã€‚

<style>#mermaid-1768965539700{font-family:sans-serif;font-size:16px;fill:#333;}#mermaid-1768965539700 .error-icon{fill:#552222;}#mermaid-1768965539700 .error-text{fill:#552222;stroke:#552222;}#mermaid-1768965539700 .edge-thickness-normal{stroke-width:2px;}#mermaid-1768965539700 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1768965539700 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1768965539700 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1768965539700 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1768965539700 .marker{fill:#333333;}#mermaid-1768965539700 .marker.cross{stroke:#333333;}#mermaid-1768965539700 svg{font-family:sans-serif;font-size:16px;}#mermaid-1768965539700 .label{font-family:sans-serif;color:#333;}#mermaid-1768965539700 .label text{fill:#333;}#mermaid-1768965539700 .node rect,#mermaid-1768965539700 .node circle,#mermaid-1768965539700 .node ellipse,#mermaid-1768965539700 .node polygon,#mermaid-1768965539700 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-1768965539700 .node .label{text-align:center;}#mermaid-1768965539700 .node.clickable{cursor:pointer;}#mermaid-1768965539700 .arrowheadPath{fill:#333333;}#mermaid-1768965539700 .edgePath .path{stroke:#333333;stroke-width:1.5px;}#mermaid-1768965539700 .flowchart-link{stroke:#333333;fill:none;}#mermaid-1768965539700 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-1768965539700 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-1768965539700 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-1768965539700 .cluster text{fill:#333;}#mermaid-1768965539700 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80,100%,96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-1768965539700:root{--mermaid-font-family:sans-serif;}#mermaid-1768965539700:root{--mermaid-alt-font-family:sans-serif;}#mermaid-1768965539700 flowchart{fill:apa;}</style>
