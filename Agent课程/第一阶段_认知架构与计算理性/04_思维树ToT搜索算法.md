# ç¬¬04è¯¾ï¼šæ€ç»´æ ‘ (ToT) æœç´¢ç®—æ³•

**å…³é”®è¯**ï¼šSearch, BFS/DFS, Heuristic Function, çŠ¶æ€ç©ºé—´éå†

---

## ç¬”è®°åŒºåŸŸ

ä½ å¥½ã€‚è¿™æ˜¯ã€ŠAI Agent æ·±åº¦æ¶æ„ä¸æ•°å­¦åŸç†ã€‹çš„ç¬¬å››è¯¾ã€‚

åœ¨å‰å‡ è¯¾ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº† Prompt Engineeringï¼ˆéšå¼è´å¶æ–¯æ¨ç†ï¼‰å’Œ Chain of Thoughtï¼ˆçº¿æ€§æ¨ç†è·¯å¾„ï¼‰ã€‚
**èƒŒæ™¯é©±åŠ¨**ï¼š
CoT çš„æ ¸å¿ƒç¼ºé™·åœ¨äºå®ƒæ˜¯**è´ªå©ªçš„ï¼ˆGreedyï¼‰**å’Œ**çº¿æ€§çš„ï¼ˆLinearï¼‰**ã€‚

1. **å±€éƒ¨æœ€ä¼˜é™·é˜±**ï¼šCoT åœ¨æ¯ä¸€æ­¥ $t$ å€¾å‘äºé€‰æ‹©å±€éƒ¨æ¦‚ç‡æœ€é«˜çš„è·¯å¾„ï¼Œä¸€æ—¦æŸä¸€æ­¥æ¨ç†å‡ºç°åå·®ï¼ˆHallucination æˆ– é€»è¾‘è·³è·ƒï¼‰ï¼Œæ¨¡å‹ç¼ºä¹**å›æº¯ï¼ˆBacktrackingï¼‰**æœºåˆ¶æ¥çº æ­£é”™è¯¯ï¼Œå¯¼è‡´é”™è¯¯çº§è”ï¼ˆError Cascadingï¼‰ã€‚
2. **ç¼ºä¹å…¨å±€è§„åˆ’**ï¼šå¯¹äºåƒæ•°å­¦è¯æ˜ã€ä»£ç ç”Ÿæˆæˆ–å¤æ‚é€»è¾‘è°œé¢˜ï¼ˆå¦‚ 24ç‚¹æ¸¸æˆï¼‰è¿™ç±»ä»»åŠ¡ï¼Œå¾€å¾€éœ€è¦**å‰ç»ï¼ˆLookaheadï¼‰**å’Œ**å…¨å±€è¯„ä¼°**ï¼Œå•çº¯çš„è‡ªå›å½’ç”Ÿæˆæ— æ³•èƒœä»»ã€‚

**çªç ´ç‚¹**ï¼š
å°† LLM ä»å•çº¯çš„â€œç”Ÿæˆå™¨â€é™çº§ä¸ºâ€œçŠ¶æ€è½¬ç§»å™¨â€å’Œâ€œå¯å‘å¼è¯„ä¼°å™¨â€ï¼Œå¼•å…¥ç»å…¸äººå·¥æ™ºèƒ½ä¸­çš„**æ ‘æœç´¢ç®—æ³•ï¼ˆTree Search Algorithmsï¼‰**ã€‚è¿™å°±æ˜¯ **Tree of Thoughts (ToT)**ã€‚

---

# ğŸ§  ç¬¬04è¯¾ï¼šæ€ç»´æ ‘ (ToT) æœç´¢ç®—æ³•

### 1. ç†è®ºæ ¸å¿ƒï¼šåœ¨è¯­ä¹‰ç©ºé—´ä¸­çš„å¯å‘å¼æœç´¢

#### 1.1 é—®é¢˜å½¢å¼åŒ–ï¼šçŠ¶æ€ç©ºé—´æœç´¢

æˆ‘ä»¬å°†å¤æ‚çš„æ¨ç†ä»»åŠ¡å»ºæ¨¡ä¸ºåœ¨**æ€ç»´ç©ºé—´ï¼ˆThought Spaceï¼‰**ä¸­çš„æœç´¢é—®é¢˜ã€‚å®šä¹‰ä¸ºä¸€ä¸ªå››å…ƒç»„ $\mathcal{T} = \langle S, A, P, V \rangle$ï¼š

1. **çŠ¶æ€ç©ºé—´ (State Space, $S$)**ï¼š
   å½“å‰çš„éƒ¨åˆ†è§£ã€‚$s = [x, z_{1 \dots i}]$ï¼Œå…¶ä¸­ $x$ æ˜¯è¾“å…¥ï¼Œ$z$ æ˜¯æ€ç»´æ­¥éª¤ã€‚
2. **åŠ¨ä½œç©ºé—´ (Action Space, $A$)**ï¼š
   è¿™ä¸€æ­¥ä¸ä¼ ç»Ÿ RL ä¸åŒã€‚åŠ¨ä½œä¸æ˜¯è¾“å‡ºä¸€ä¸ª Tokenï¼Œè€Œæ˜¯ç”Ÿæˆ**ä¸€ä¸ªæ€ç»´æ­¥éª¤ï¼ˆA Thought Stepï¼‰**ã€‚
   $z_{i+1} \in A(s_i)$ã€‚ä¾‹å¦‚åœ¨å†™ä»£ç æ—¶ï¼Œä¸€ä¸ª Action å¯èƒ½æ˜¯ä¸€æ®µå®Œæ•´çš„å‡½æ•°å®šä¹‰ã€‚
3. **è½¬ç§»æ¨¡å‹ (Transition Model, $P_\theta$)**ï¼š
   ç”± LLM æä¾›ã€‚$P_\theta(s' | s, a)$ã€‚å³åŸºäºå½“å‰çŠ¶æ€ç”Ÿæˆä¸‹ä¸€ä¸ªæ€ç»´æ­¥éª¤ã€‚
   $$
   z_{i+1} \sim \text{LLM}(z_{i+1} | x, z_{1 \dots i})
   $$
4. **ä»·å€¼å‡½æ•° (Value Function, $V$)**ï¼š
   è¿™æ˜¯ ToT çš„çµé­‚ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¯å‘å¼å‡½æ•°æ¥è¯„ä¼°çŠ¶æ€ $s$ è·ç¦»è§£å†³é—®é¢˜è¿˜æœ‰å¤šè¿œã€‚
   $$
   V(s) \in [0, 1] \quad \text{or} \quad V(s) \in \mathbb{R}
   $$

#### 1.2 æ ¸å¿ƒå‡è®¾

ToT å»ºç«‹åœ¨ä¸¤ä¸ªæ ¸å¿ƒå‡è®¾ä¹‹ä¸Šï¼š

1. **åˆ†è§£å‡è®¾**ï¼šå¤æ‚é—®é¢˜å¯ä»¥åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤ï¼ˆThoughtsï¼‰ã€‚
2. **è¯„ä¼°å‡è®¾**ï¼šLLM è¯†åˆ«â€œå¥½çŠ¶æ€â€çš„èƒ½åŠ›å¼ºäºå…¶ç›´æ¥ç”Ÿæˆâ€œå¥½ç»“æœâ€çš„èƒ½åŠ›ã€‚ï¼ˆç±»ä¼¼äº P vs NP é—®é¢˜ï¼šéªŒè¯è§£æ¯”æ±‚è§£å®¹æ˜“ï¼‰ã€‚

#### 1.3 ç®—æ³•æµç¨‹ (BFS å˜ä½“)

ä»¥å¹¿åº¦ä¼˜å…ˆæœç´¢ï¼ˆBFSï¼‰ä¸ºä¾‹ï¼ŒToT çš„æ•°å­¦è¿‡ç¨‹å¦‚ä¸‹ï¼š

å¯¹äºæ¯ä¸€æ­¥ $t = 1 \dots T$:

1. **Generate (Expansion)**: å¯¹å½“å‰å€™é€‰é›† $S_t$ ä¸­çš„æ¯ä¸ªçŠ¶æ€ $s$ï¼Œåˆ©ç”¨ LLM ç”Ÿæˆ $k$ ä¸ªå€™é€‰æ€ç»´ $z^{(1 \dots k)}$ã€‚
2. **Evaluate (Heuristic)**: åˆ©ç”¨ LLM å¯¹æ¯ä¸ªæ–°çŠ¶æ€ $s \cup \{z^{(j)}\}$ è¿›è¡Œè¯„åˆ†æˆ–æŠ•ç¥¨ã€‚
3. **Select (Pruning)**: æ ¹æ®è¯„åˆ†ä¿ç•™ Top-$b$ ä¸ªçŠ¶æ€è¿›å…¥ $S_{t+1}$ã€‚

---

### 2. æ¶æ„è§£å‰–ä¸å·¥ç¨‹åº”ç”¨

#### 2.1 å·¥ç¨‹æµæ°´çº¿ (Pipeline)

åœ¨å®é™…å·¥ç¨‹ä¸­ï¼ŒToT åŒ…å«å››ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

1. **Decomposer (åˆ†è§£å™¨)**ï¼šå°† Prompt è§£æä¸ºç‰¹å®šçš„æ­¥éª¤æ ¼å¼ã€‚
2. **Generator (ç”Ÿæˆå™¨)**ï¼š
   * *Sample (i.i.d)*: ç‹¬ç«‹é‡‡æ · $k$ æ¬¡ï¼ˆé€‚ç”¨äºåˆ›ä½œå‹ä»»åŠ¡ï¼Œå¢åŠ å¤šæ ·æ€§ï¼‰ã€‚
   * *Propose (Sequential)*: ç”¨ Few-shot Prompt è®© LLM ä¸€æ¬¡æ€§åˆ—ä¸¾ $k$ ä¸ªé€‰é¡¹ï¼ˆé€‚ç”¨äºé€»è¾‘å‹ä»»åŠ¡ï¼‰ã€‚
3. **Evaluator (è¯„ä¼°å™¨)**ï¼š
   * *Value*: ç»™å®šçŠ¶æ€ï¼Œè¾“å‡ºæ ‡é‡è¯„åˆ†ï¼ˆå¦‚ 1-10ï¼Œæˆ– Sure/Likely/Impossibleï¼‰ã€‚
   * *Vote*: ç»™å®šå¤šä¸ªçŠ¶æ€ï¼Œè®© LLM æŠ•ç¥¨é€‰å‡ºæœ€å¥½çš„ã€‚
4. **Controller (æ§åˆ¶å™¨)**ï¼šå®ç° BFSã€DFS æˆ– MCTS é€»è¾‘çš„ Python ä»£ç ã€‚

#### 2.2 ç³»ç»Ÿè®¾è®¡å›¾ (Mermaid)

```mermaid
graph TD
    Input[Input x] --> Controller
  
    subgraph ToT System
        Controller{Search Algo<br>BFS/DFS}
      
        Controller -->|State s| Generator[Thought Generator<br>Propose k steps]
        Generator -->|Candidates z1..zk| Evaluator[State Evaluator]
      
        Evaluator -->|Value V| Controller
      
        Controller -->|Prune| Memory[Active States Queue]
        Memory -->|Next Iteration| Controller
    end
  
    Controller -->|Target Reached| Output[Final Trajectory]
  
    style Controller fill:#f9f,stroke:#333
    style Evaluator fill:#bbf,stroke:#333
```

---

### 3. ä»£ç å®æˆ˜ (Implementation Lab)

æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªåŸºäº **BFS (Beam Search)** çš„é€šç”¨ ToT æ¡†æ¶ã€‚ä¸ºäº†ç¡¬æ ¸å±•ç¤ºåŸç†ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å®ç°çŠ¶æ€ç®¡ç†å’Œæœç´¢é€»è¾‘ã€‚

**åœºæ™¯**ï¼š24ç‚¹æ¸¸æˆï¼ˆä½¿ç”¨ 4 ä¸ªæ•°å­—é€šè¿‡åŠ å‡ä¹˜é™¤å¾—åˆ° 24ï¼‰ã€‚

```python
import itertools
from typing import List, Tuple, Dict
import heapq

class ToTNode:
    def __init__(self, state: str, value: float, history: List[str]):
        self.state = state   # å½“å‰å‰©ä¸‹çš„æ•°å­—ï¼Œå¦‚ "10 14"
        self.value = value   # è¯„ä¼°åˆ†æ•°
        self.history = history # æ¨ç†è½¨è¿¹ï¼Œå¦‚ ["4+9=13", "13+1=14"]

    def __lt__(self, other):
        # ç”¨äºä¼˜å…ˆé˜Ÿåˆ—ï¼ˆè™½ç„¶BFSç”¨listæ’åºæ›´å¤šï¼Œä½†ä¸ºäº†æ¥å£é€šç”¨æ€§ï¼‰
        return self.value < other.value

class TreeOfThoughts:
    def __init__(self, llm_model, beam_width=5, max_depth=4):
        self.llm = llm_model
        self.b = beam_width
        self.max_steps = max_depth

    def generate_thoughts(self, node: ToTNode, k=3) -> List[str]:
        """
        [Generator]: ç»™å®šå½“å‰çŠ¶æ€ï¼Œç”Ÿæˆ k ä¸ªå¯èƒ½çš„ä¸‹ä¸€æ­¥è¿ç®—ã€‚
        Prompt Engineering: "Current numbers: 4 9 10 13. Generate 3 possible next steps."
        """
        prompt = f"Current numbers: {node.state}. History: {node.history}. Propose {k} next valid operations."
        # mock_llm_call(prompt) -> returns ["4+9=13 (left: 13, 10, 13)", "10-4=6 (left: 6, 9, 13)"]
        return self.llm.propose(prompt, n=k)

    def evaluate_states(self, candidates: List[Tuple[str, List[str]]]) -> List[float]:
        """
        [Evaluator]: è¯„ä¼°çŠ¶æ€æ˜¯å¦æœ‰å¸Œæœ›åˆ°è¾¾ 24ã€‚
        Prompt Engineering: "Numbers: 13 10 13. Goal: 24. Is it possible? Score 0.0 to 1.0"
        """
        prompts = [f"Numbers: {state}. Can we reach 24? Rate 0.0-1.0" for state, _ in candidates]
        # mock_llm_value(prompts) -> returns [0.9, 0.1, ...]
        return self.llm.value(prompts)

    def solve(self, initial_numbers: str):
        # åˆå§‹åŒ–
        current_layer = [ToTNode(state=initial_numbers, value=1.0, history=[])]
      
        for step in range(self.max_steps):
            print(f"--- Depth {step} | Candidates: {len(current_layer)} ---")
          
            # 1. Expand (Generate)
            next_candidates = [] # List of (new_state, new_history)
            for node in current_layer:
                # æ£€æŸ¥æ˜¯å¦å·²è§£å†³
                if self.check_success(node.state):
                    return node.history
              
                thoughts = self.generate_thoughts(node)
                for thought in thoughts:
                    # è§£æ thought å¾—åˆ° new_state (è¿™ä¸€æ­¥é€šå¸¸éœ€è¦ç®€å•çš„è§„åˆ™è§£æ)
                    new_state = self.parse_state(thought) 
                    new_history = node.history + [thought]
                    next_candidates.append((new_state, new_history))

            if not next_candidates:
                break

            # 2. Evaluate
            # è¿™é‡Œçš„å…³é”®æ˜¯ï¼šæˆ‘ä»¬æ˜¯åœ¨è¯„ä¼°â€œæœªæ¥â€ï¼Œè€Œä¸æ˜¯è¯„ä¼°â€œè¿‡å»â€
            scores = self.evaluate_states(next_candidates)

            # 3. Prune (Select Top-b)
            # æ„å»ºæ–°èŠ‚ç‚¹
            new_nodes = []
            for i, (new_state, new_hist) in enumerate(next_candidates):
                new_nodes.append(ToTNode(new_state, scores[i], new_hist))
          
            # æ’åºå¹¶æˆªæ–­
            new_nodes.sort(key=lambda x: x.value, reverse=True)
            current_layer = new_nodes[:self.b]
          
            # Debug log
            print(f"Best state: {current_layer[0].state} (Score: {current_layer[0].value})")

        return None

    def check_success(self, state):
        return "24" in state and len(state.split()) == 1
  
    def parse_state(self, thought):
        # Mock parsing: "4+9=13 (left: 13 10 13)" -> "13 10 13"
        return thought.split("left:")[1].strip(")")

# æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®—æ³•éª¨æ¶ã€‚åœ¨çœŸå®å·¥ç¨‹ä¸­ï¼ŒEvaluator æå…¶éš¾è°ƒï¼Œéœ€è¦ Few-shot CoT æ¥å¼•å¯¼è¯„åˆ†ã€‚
```

---

### 4. Paper Drivenï¼šæ ¸å¿ƒè®ºæ–‡ä¸è´¡çŒ®

1. **Yao et al. (NeurIPS 2023)**: *Tree of Thoughts: Deliberate Problem Solving with Large Language Models*.
   * **è´¡çŒ®**ï¼šæ­£å¼æå‡º ToT æ¡†æ¶ã€‚å¯¹æ¯”äº† IO, CoT, CoT-SC, ToT å››ç§æ¨¡å¼ã€‚
   * **æ•°æ®**ï¼šåœ¨ Game of 24 ä¸­ï¼ŒCoT æˆåŠŸç‡ä»… 4%ï¼ŒToT æå‡è‡³ 74%ã€‚è¯æ˜äº†åœ¨éœ€è¦è§„åˆ’çš„ä»»åŠ¡ä¸­ï¼Œæœç´¢ä¼˜äºç”Ÿæˆã€‚
2. **Long (2023)**: *Large Language Model Guided Tree-of-Thought*.
   * **è´¡çŒ®**ï¼šå¼•å…¥äº† **RL å¼ºåŒ–å­¦ä¹ ** çš„æ¦‚å¿µï¼Œåˆ©ç”¨ Policy Gradient æ¥å¾®è°ƒ ToT çš„ Controllerã€‚
3. **Zhou et al. (2023)**: *Language Agent Tree Search (LATS)*.
   * **æ ¸å¿ƒå‡çº§**ï¼šå°†ç®€å•çš„ BFS/DFS å‡çº§ä¸º **MCTS (è’™ç‰¹å¡æ´›æ ‘æœç´¢)**ã€‚
   * **åŸç†**ï¼šå¼•å…¥åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ã€‚å½“å¶å­èŠ‚ç‚¹è¢«åˆ¤å®šä¸ºå¤±è´¥/æˆåŠŸæ—¶ï¼Œä»·å€¼ä¼šå‘ä¸Šä¼ æ’­æ›´æ–°çˆ¶èŠ‚ç‚¹çš„ Valueã€‚è¿™è§£å†³äº† BFS è´ªå©ªã€ç¼ºä¹é•¿è¿œè§†é‡çš„é—®é¢˜ã€‚

---

### 5. Critical Thinkingï¼šæ‰¹åˆ¤æ€§åˆ†æ

ToT è™½ç„¶å¼ºå¤§ï¼Œä½†ä¸æ˜¯é“¶å¼¹ã€‚

1. **æ€§èƒ½ç“¶é¢ˆ (Latency & Cost)**:
   * **åˆ†æ**ï¼šToT çš„è®¡ç®—å¤æ‚åº¦æ˜¯ $O(b^d)$ã€‚å¦‚æœ $b=5, d=5$ï¼Œç†è®ºä¸Šå¯èƒ½äº§ç”Ÿæ•°åƒæ¬¡ LLM è°ƒç”¨ã€‚è¿™åœ¨å³æ—¶å“åº”ç³»ç»Ÿä¸­æ˜¯ä¸å¯æ¥å—çš„ã€‚
   * **è§£å†³æ€è·¯**ï¼š**å‰ªæä¼˜åŒ–**ã€‚å¦‚æœ $V(s) < \epsilon$ï¼Œç›´æ¥ä¸¢å¼ƒï¼Œä¸è¿›è¡Œæ‰©å±•ã€‚æˆ–è€…ä½¿ç”¨ **Speculative Decoding**ï¼Œç”¨å°æ¨¡å‹ç”Ÿæˆæ ‘ï¼Œå¤§æ¨¡å‹è¯„ä¼°æ ‘ã€‚
2. **è¯„ä¼°å¹»è§‰ (Evaluation Hallucination)**:
   * **å±€é™**ï¼šToT æå…¶ä¾èµ– Evaluator çš„å‡†ç¡®æ€§ã€‚å¦‚æœ LLM è‡ªèº«æ— æ³•åˆ¤æ–­â€œè¿™ä¸€æ­¥èµ°å¾—å¥½ä¸å¥½â€ï¼ˆæ¯”å¦‚å¤æ‚çš„æ•°å­¦è¯æ˜ï¼‰ï¼ŒToT å°±ä¼šé€€åŒ–ä¸ºéšæœºæœç´¢ã€‚
   * **è§£å†³æ€è·¯**ï¼š**External Verifier**ã€‚ä¸è¦è®© LLM ç»™ä»£ç æ‰“åˆ†ï¼Œç”¨ Unit Test ç»™ä»£ç æ‰“åˆ†ï¼›ä¸è¦è®© LLM ç®—æ•°ï¼Œç”¨ Python Calculator ç®—æ•°ã€‚å°† ToT ä¸ Tool Use ç»“åˆã€‚
3. **Context Window çˆ†ç‚¸**:
   * **å±€é™**ï¼šæ ‘çš„æ·±å±‚èŠ‚ç‚¹éœ€è¦æºå¸¦ä» Root å¼€å§‹çš„å®Œæ•´å†å²ã€‚
   * **è§£å†³æ€è·¯**ï¼š**State Abstraction**ã€‚åªä¼ é€’å½“å‰çŠ¶æ€ï¼ˆå¦‚ 24ç‚¹ä¸­å‰©ä¸‹çš„æ•°å­—ï¼‰ï¼Œä¸¢å¼ƒå†å²æ¨ç†è¿‡ç¨‹ï¼Œé™¤ééœ€è¦å›æº¯ã€‚

---

### 6. å‰æ²¿æ‰©å±•

* **Graph of Thoughts (GoT)**:
  ToT åªæ˜¯æ ‘ï¼ŒèŠ‚ç‚¹é—´æ²¡æœ‰æ¨ªå‘è”ç³»ã€‚GoT å…è®¸**æ€ç»´èšåˆ (Aggregation)**ã€‚ä¾‹å¦‚ï¼Œç”Ÿæˆä¸‰ä¸ªä¸åŒçš„æ‘˜è¦ï¼ˆåˆ†æ”¯ï¼‰ï¼Œç„¶åç”¨ä¸€ä¸ªæ–°èŠ‚ç‚¹å°†è¿™ä¸‰ä¸ªæ‘˜è¦åˆå¹¶ä¸ºä¸€ä¸ªæ›´å¥½çš„æ‘˜è¦ã€‚è¿™æ„å»ºäº†ä¸€ä¸ª DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ã€‚
* **Algorithm of Thoughts (AoT)**:
  ä¸ºäº†è§£å†³ ToT çš„è®¡ç®—æˆæœ¬ï¼ŒAoT è¯•å›¾é€šè¿‡ Prompt Engineering å¼ºè¿« LLM åœ¨**ä¸€æ¬¡ Context ç”Ÿæˆ**ä¸­æ¨¡æ‹Ÿ DFS çš„æœç´¢è¿‡ç¨‹ï¼ˆè‡ªå›å½’åœ°ç”Ÿæˆæœç´¢è½¨è¿¹ï¼‰ï¼Œè¯•å›¾å…¼å¾— CoT çš„é€Ÿåº¦å’Œ ToT çš„å¹¿åº¦ã€‚
* **AlphaZero-like Agent**:
  æœ€å‰æ²¿çš„ç ”ç©¶æ­£åœ¨å°è¯•ç”¨è®­ç»ƒå¥½çš„ **Value Network** (ç±»ä¼¼äº AlphaGo çš„ Value Head) æ¥æ›¿ä»£ Prompt-based Evaluatorï¼Œå½»åº•è§£å†³è¯„ä¼°ä¸å‡†çš„é—®é¢˜ã€‚

---

### æ€»ç»“

ToT çš„æœ¬è´¨æ˜¯å°† **System 1 çš„ç›´è§‰ï¼ˆç”Ÿæˆï¼‰** ä¸ **System 2 çš„é€»è¾‘ï¼ˆæœç´¢ï¼‰** è§£è€¦ã€‚
å·¥ç¨‹ä¸Šï¼ŒToT æ˜¯ä¸€ç§**ç”¨æ¨ç†æ—¶é—´ï¼ˆInference Computeï¼‰æ¢å–æ™ºèƒ½ï¼ˆIntelligenceï¼‰**çš„æ¶æ„æ¨¡å¼ã€‚

ä¸‹ä¸€è¯¾ï¼Œæˆ‘ä»¬å°†æ·±å…¥ **è®°å¿†ç³»ç»Ÿ (Memory Systems)**ï¼Œæ¢è®¨å¦‚ä½•åˆ©ç”¨ RAG å’Œå‘é‡æ•°æ®åº“ä¸ºè¿™äº›æœç´¢ç®—æ³•æä¾›æ— é™çš„çŸ¥è¯†æ”¯æŒã€‚
