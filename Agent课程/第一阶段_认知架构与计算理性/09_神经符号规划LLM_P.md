
# ç¬¬09è¯¾ï¼šç¥ç»ç¬¦å·è§„åˆ’ (LLM+P)

**å…³é”®è¯**ï¼šPDDL, Symbolic Planning, Fast-Downward, é•¿é“¾å› æœæ¨ç†

---

## ç¬”è®°åŒºåŸŸ

ä½ å¥½ã€‚è¿™æ˜¯ã€ŠAI Agent æ·±åº¦æ¶æ„ä¸æ•°å­¦åŸç†ã€‹çš„ç¬¬ä¹è¯¾ã€‚

åœ¨å‰é¢çš„è¯¾ç¨‹ï¼ˆMCTS, ToTï¼‰ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨å°è¯•â€œå¼ºæ¨â€LLM çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ä½†æ— è®ºå¦‚ä½• Promptingï¼ŒLLM æœ¬è´¨ä¸Šä»ç„¶æ˜¯ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œå®ƒæ²¡æœ‰**â€œç¡¬é€»è¾‘ï¼ˆHard Logicï¼‰â€**çº¦æŸã€‚è¿™æ„å‘³ç€å®ƒåœ¨å¤„ç†é•¿é“¾è·¯ã€å¼ºçº¦æŸçš„ä»»åŠ¡ï¼ˆå¦‚ç‰©æµè°ƒåº¦ã€æœºå™¨äººè·¯å¾„è§„åˆ’ï¼‰æ—¶ï¼Œéšæ—¶å¯èƒ½å‡ºç°â€œå¹»è§‰â€â€”â€”æ¯”å¦‚è®©æœºå™¨äººç©¿å¢™è€Œè¿‡ï¼Œæˆ–è€…ç§»åŠ¨ä¸€ä¸ªè¢«å‹åœ¨åº•ä¸‹çš„ç®±å­ã€‚

**èƒŒæ™¯é©±åŠ¨**ï¼š

* **æŒ‘æˆ˜ (Challenge)**ï¼šLLM ç¼ºä¹**ç‰©ç†ä¸€è‡´æ€§ï¼ˆPhysical Consistencyï¼‰**å’Œ**çŠ¶æ€å›æº¯çš„å®Œå¤‡æ€§**ã€‚å•çº¯é  LLM ç”Ÿæˆ Planï¼Œæ— æ³•ä¿è¯ Plan çš„å¯æ‰§è¡Œæ€§ï¼ˆFeasibilityï¼‰å’Œæœ€ä¼˜æ€§ï¼ˆOptimalityï¼‰ã€‚
* **çªç ´ç‚¹ (Breakthrough)**ï¼š**ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½ï¼ˆNeuro-Symbolic AIï¼‰**ã€‚
  * **Neuro (LLM)**ï¼šæ“…é•¿è¯­ä¹‰ç†è§£ã€å¸¸è¯†æ¨ç†ã€å°†è‡ªç„¶è¯­è¨€ç¿»è¯‘æˆå½¢å¼åŒ–è¯­è¨€ã€‚
  * **Symbolic (Planner)**ï¼šæ“…é•¿åœ¨å°é—­ä¸–ç•Œå‡è®¾ä¸‹è¿›è¡Œå®Œç¾çš„é€»è¾‘æœç´¢ï¼ˆå¦‚ A* ç®—æ³•ï¼‰ã€‚
* **æ”¹è¿›æ–¹å‘**ï¼š
  **LLM+P (Large Language Models + Classical Planners)**ã€‚å°† LLM ä»â€œæ±‚è§£è€…â€é™çº§ä¸ºâ€œç¿»è¯‘å™¨â€ï¼Œå°†çœŸæ­£çš„â€œæ±‚è§£â€å·¥ä½œå¤–åŒ…ç»™ç»å…¸çš„ AI è§„åˆ’å™¨ï¼ˆå¦‚ Fast Downwardï¼‰ã€‚

---

# ğŸ§  ç¬¬09è¯¾ï¼šç¥ç»ç¬¦å·è§„åˆ’ (LLM+P)

### 1. ç†è®ºæ ¸å¿ƒï¼šPDDL ä¸ å½¢å¼åŒ–è§„åˆ’

#### 1.1 é—®é¢˜å½¢å¼åŒ–ï¼šSTRIPS è§„åˆ’é—®é¢˜

åœ¨ç»å…¸ AI ä¸­ï¼Œä¸€ä¸ªè§„åˆ’é—®é¢˜è¢«å½¢å¼åŒ–ä¸ºå…ƒç»„ $\Pi = \langle \mathcal{D}, \mathcal{P} \rangle$ã€‚

1. **Domain (é¢†åŸŸ, $\mathcal{D}$)**ï¼šå®šä¹‰äº†ä¸–ç•Œè¿ä½œçš„ç‰©ç†è§„åˆ™ã€‚

   * **Predicates (è°“è¯)**ï¼šæè¿°çŠ¶æ€çš„åŸå­ï¼Œä¾‹å¦‚ `On(x, y)`, `Clear(x)`ã€‚
   * **Actions (åŠ¨ä½œ)**ï¼šå®šä¹‰ä¸º $\langle \text{Pre}, \text{Add}, \text{Del} \rangle$ã€‚

     * Preconditions (å‰æ): åŠ¨ä½œæ‰§è¡Œå‰å¿…é¡»ä¸ºçœŸã€‚
     * Effects (Add/Del): åŠ¨ä½œæ‰§è¡ŒåçŠ¶æ€çš„æ”¹å˜ã€‚
   * *æ•°å­¦è¡¨è¾¾*ï¼š

     $$
     \text{Action}(a): S \to S' \quad \text{iff} \quad \text{Pre}(a) \subseteq S
     $$

     $$
     S' = (S \setminus \text{Del}(a)) \cup \text{Add}(a)
     $$
2. **Problem (é—®é¢˜, $\mathcal{P}$)**ï¼šå®šä¹‰äº†å…·ä½“çš„ä»»åŠ¡å®ä¾‹ã€‚

   * **Objects**: æ¶‰åŠçš„å®ä½“ï¼ˆå¦‚ block_a, block_bï¼‰ã€‚
   * **Init State ($S_0$)**: åˆå§‹ä¸–ç•ŒçŠ¶æ€ã€‚
   * **Goal State ($G$)**: ç›®æ ‡çŠ¶æ€é€»è¾‘å…¬å¼ã€‚

#### 1.2 LLM+P çš„æ ¸å¿ƒå‡è®¾

LLM æ— æ³•ç›´æ¥åœ¨å¤§è„‘ä¸­æ¨¡æ‹Ÿ $S \to S'$ çš„ç²¾ç¡®çŠ¶æ€è½¬ç§»ï¼ˆç‰¹åˆ«æ˜¯æ­¥éª¤ $N > 10$ æ—¶ï¼‰ã€‚ä½†æ˜¯ï¼ŒLLM éå¸¸æ“…é•¿åš**è¯­ä¹‰åŒæ„æ˜ å°„ï¼ˆSemantic Isomorphism Mappingï¼‰**ã€‚

å³å­˜åœ¨æ˜ å°„å‡½æ•° $f_\theta$ï¼š

$$
f_\theta: \text{Natural Language (NL)} \to \text{PDDL (Planning Domain Definition Language)}
$$

ä¸€æ—¦é—®é¢˜è¢«è½¬åŒ–ä¸º PDDLï¼Œç»å…¸çš„è§„åˆ’å™¨ï¼ˆPlannerï¼‰å¯ä»¥åœ¨æ¯«ç§’çº§å†…ä¿è¯æ‰¾åˆ°æœ€ä¼˜è§£ï¼ˆOptimal Planï¼‰ã€‚

---

### 2. æ¶æ„è§£å‰–ä¸å·¥ç¨‹åº”ç”¨

#### 2.1 ç³»ç»Ÿæµæ°´çº¿ (Pipeline)

LLM+P çš„æ¶æ„æ˜¯ä¸€ä¸ªå…¸å‹çš„**ç¼–è¯‘å™¨æ¨¡å¼ï¼ˆCompiler Patternï¼‰**ï¼š

1. **Translation (LLM)**: å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚ + é¢„å®šä¹‰çš„ Domain æè¿° $\to$ ç”Ÿæˆ `problem.pddl` æ–‡ä»¶ã€‚
2. **Planning (Solver)**: è°ƒç”¨å¤–éƒ¨æ±‚è§£å™¨ï¼ˆå¦‚ Fast Downward, Pyperplanï¼‰ $\to$ ç”Ÿæˆ Action Sequenceã€‚
3. **Interpretation (LLM)**: å°† PDDL Action Sequence $\to$ è‡ªç„¶è¯­è¨€æè¿°æˆ–æœºå™¨äººæŒ‡ä»¤ã€‚

#### 2.2 æ¶æ„å›¾è§£ (Mermaid)

```mermaid
graph TD
    User["User: Move block A onto B"] --> Context
    Domain["Fixed Domain.pddl<br>(Rules of Physics)"] --> Context
    Context_Prompt[Context: ICL Examples] --> Context
  
    Context --> LLM_Trans[LLM: Translator]
  
    LLM_Trans -->|Generate| Prob_PDDL["Problem.pddl<br>(Init/Goal State)"]
  
    Prob_PDDL --> Planner{"Classical Planner<br>(Fast Downward)"}
    Domain --> Planner
  
    Planner -->|"Search (A*)"| Plan["Plan Trace:<br>(pick-up a)<br>(stack a b)"]
    Planner -- Error --> Feedback[Syntactic Error]
    Feedback --> LLM_Trans
  
    Plan --> Executor[Robot / Application]
```

#### 2.3 å·¥ç¨‹åº”ç”¨ï¼šè¾“å…¥è¾“å‡ºè¯¦è§£

**åœºæ™¯**ï¼šRobotic Arm Blocksworld (æœºæ¢°è‡‚æ­ç§¯æœ¨)ã€‚

* **è¾“å…¥ (Input)**:

  * **Prompt**: åŒ…å« `domain.pddl` çš„æ–‡æœ¬ï¼ˆå®šä¹‰äº† pickup, stack, unstack ç­‰æ“ä½œé€»è¾‘ï¼‰ï¼Œä»¥åŠå‡ ä¸ª NL $\to$ PDDL çš„ Few-shot ç¤ºä¾‹ã€‚
  * **User Query**: "There are 3 blocks. Block A is on the table. Block B is on A. Block C is on the table. I want to have A on B, and B on C."
* **æ¨¡å‹è¾“å‡º (LLM Output)**:
  LLM ä¸éœ€è¦è¾“å‡º "First, I pick up B..."ï¼Œè€Œæ˜¯è¾“å‡ºçº¯ä»£ç ï¼š

  ```lisp
  (define (problem blocksworld-prob)
    (:domain blocksworld)
    (:objects a b c)
    (:init (on-table a) (on b a) (on-table c) (clear b) (clear c) (handempty))
    (:goal (and (on a b) (on b c)))
  )
  ```

* **æ±‚è§£å™¨æ“ä½œ**:
  è¿è¡Œ `fast-downward --alias seq-sat-llama problem.pddl`ã€‚
  æ±‚è§£å™¨åˆ©ç”¨å¯å‘å¼æœç´¢ï¼ˆå¦‚ $h_{ff}$ å¯å‘å¼ï¼‰ï¼Œæ¢ç´¢çŠ¶æ€ç©ºé—´ã€‚
* **æœ€ç»ˆç»“æœ**:

  ```lisp
  (unstack b a)
  (putdown b)
  (pickup a)
  (stack a b)
  (pickup b)
  (stack b c)
  ```

  è¿™æ˜¯ä¸€ä¸ª**ç»å¯¹æ­£ç¡®**çš„åºåˆ—ï¼Œä¸å¯èƒ½å‡ºç°â€œæ‰‹ä¸­å·²æœ‰ç‰©ä½“æ—¶å†å»æŠ“ç‰©ä½“â€çš„é€»è¾‘é”™è¯¯ã€‚

---

### 3. Code & Engineeringï¼šå®ç° LLM+P æ¡¥æ¥å™¨

ä¸ºäº†è®©ç ”ä¸‰å­¦ç”Ÿç†è§£æ ¸å¿ƒï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ª Python ç±»ï¼Œå®ƒç®¡ç† PDDL çš„ç”Ÿæˆå¹¶è°ƒç”¨è½»é‡çº§ PDDL æ±‚è§£å™¨åº“ï¼ˆ`pyperplan` æˆ–æ¨¡æ‹Ÿæ¥å£ï¼‰ã€‚

**å…³é”®ç‚¹**ï¼šPrompt å¿…é¡»å¼ºåˆ¶ LLM è¾“å‡ºä¸¥æ ¼ç¬¦åˆ PDDL è¯­æ³•çš„ S-Expressionã€‚

```python
import subprocess
import os
from typing import List

class PDDLPlannerAgent:
    def __init__(self, llm_client, domain_pddl_path: str):
        self.llm = llm_client
        # 1. åŠ è½½ Domain å®šä¹‰ï¼ˆç‰©ç†è§„åˆ™é€šå¸¸æ˜¯ç¡¬ç¼–ç æˆ–ä¸“å®¶å†™å¥½çš„ï¼‰
        with open(domain_pddl_path, 'r') as f:
            self.domain_content = f.read()

    def _construct_prompt(self, user_task: str) -> str:
        """
        ICL Prompting: æ•™ LLM å¦‚ä½•å°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸º PDDL Problem
        """
        return f"""
        You are an expert in PDDL (Planning Domain Definition Language).
        Given the following domain definition:
        {self.domain_content}

        And these examples:
        User: "Block A is on the table. B is on A."
        PDDL:
        (define (problem p1) (:domain blocksworld) (:objects a b) 
        (:init (on-table a) (on b a) (clear b) (handempty)) (:goal ...))

        Task: Translate this natural language description into a valid PDDL problem.
        User: "{user_task}"
        Output only the code block.
        PDDL:
        """

    def plan(self, user_task: str) -> List[str]:
        # Step 1: LLM Translation
        prompt = self._construct_prompt(user_task)
        problem_pddl_str = self.llm.generate(prompt)
    
        # Save to temporary file
        with open("problem.pddl", "w") as f:
            f.write(problem_pddl_str)

        # Step 2: External Solver Execution
        # è¿™é‡Œå‡è®¾å®‰è£…äº† fast-downward æˆ– pyperplan
        # å®é™…å·¥ç¨‹ä¸­éœ€å¤„ç† Solver çš„ Stdout/Stderr
        try:
            print(">>> Running Classical Planner...")
            # æ¨¡æ‹Ÿ Solver è¿”å›ç»“æœ
            # process = subprocess.run(["pyperplan", "domain.pddl", "problem.pddl"], capture_output=True)
            # plan_trace = self._parse_solver_output(process.stdout)
            plan_trace = self._mock_solver(problem_pddl_str)
            return plan_trace
        except Exception as e:
            return [f"Planning Failed: {str(e)}"]

    def _mock_solver(self, problem_str):
        # æ¨¡æ‹Ÿæ±‚è§£å™¨è¡Œä¸ºï¼šå¦‚æœè¯­æ³•æ­£ç¡®ï¼Œè¿”å›è·¯å¾„
        if "(:objects" in problem_str and "(:init" in problem_str:
            return ["(unstack b a)", "(putdown b)", "(pickup a)", "(stack a b)"]
        else:
            raise ValueError("Invalid PDDL Syntax generated by LLM")

# --- Usage ---
# domain.pddl æ˜¯é¢„å…ˆå®šä¹‰å¥½çš„
# agent = PDDLPlannerAgent(openai_client, "domain.pddl")
# actions = agent.plan("Put Block A on Block B")
# print(actions)
```

---

### 4. Paper Drivenï¼šæ ¸å¿ƒè®ºæ–‡ä¸è´¡çŒ®

1. **Liu et al. (2023)**: *LLM+P: Empowering Large Language Models with Optimal Planning Proficiency*.
   * **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†æ ‡å‡†çš„ LLM+P èŒƒå¼ã€‚
   * **å®éªŒç»“è®º**ï¼šåœ¨ Blocksworld ç­‰ç»å…¸è§„åˆ’ Benchmark ä¸Šï¼Œå•çº¯ GPT-4 çš„æˆåŠŸç‡ä¸è¶³ 30%ï¼ˆéšæ­¥æ•°å¢åŠ æŒ‡æ•°ä¸‹é™ï¼‰ï¼Œè€Œ LLM+P åªè¦è½¬æ¢æ­£ç¡®ï¼ŒæˆåŠŸç‡æ¥è¿‘ 100%ã€‚è¯æ˜äº†â€œæœ¯ä¸šæœ‰ä¸“æ”»â€ï¼šLLM åšç¿»è¯‘ï¼ŒPlanner åšæ¨ç†ã€‚
2. **Ahn et al. (Google Robotics, 2022)**: *Do As I Can, Not Just As I Say (SayCan)*.
   * **è¿æ¥ç‚¹**ï¼šè™½ç„¶ä¸æ˜¯ä¸¥æ ¼çš„ PDDLï¼Œä½† SayCan å¼•å…¥äº† **Affordance (å¯ä¾›æ€§)** çš„æ¦‚å¿µã€‚
   * **å…¬å¼**ï¼š$P(\text{Plan}| \text{User}) \propto P_{\text{LLM}}(\text{Action}|\text{User}) \cdot P_{\text{Value}}(\text{Feasible}|\text{State})$ã€‚å®ƒå°† LLM çš„è¯­ä¹‰æ¦‚ç‡ä¸æœºå™¨äººçš„æ‰§è¡ŒæˆåŠŸç‡ç»“åˆã€‚
3. **Silver et al. (2022)**: *PDDL planning with Pretrained Large Language Models (Generalized Planning)*.
   * **è¿›é˜¶**ï¼šLLM ä¸ä»…å¯ä»¥ç”Ÿæˆ Problemï¼Œç”šè‡³å¯ä»¥åœ¨å°‘æ ·æœ¬ä¸‹ç”Ÿæˆ Domain PDDLï¼ˆå³**å­¦ä¹ ç‰©ç†è§„åˆ™**ï¼‰ï¼Œè™½ç„¶ç›®å‰è¿™ä»ç„¶éå¸¸å›°éš¾ã€‚

---

### 5. Critical Thinkingï¼šæ‰¹åˆ¤æ€§åˆ†æ

LLM+P çœ‹èµ·æ¥å¾ˆç¾ï¼Œä½†æœ‰ä¸€ä¸ªå·¨å¤§çš„**é˜¿å–€ç‰æ–¯ä¹‹è¸µ**ã€‚

1. **ç¿»è¯‘ç“¶é¢ˆ (Translation Bottleneck)**:

   * **å±€é™**ï¼šç³»ç»Ÿçš„ä¸Šé™å–å†³äº LLM èƒ½å¦ç”Ÿæˆ**è¯­æ³•å®Œç¾**ä¸”**è¯­ä¹‰å‡†ç¡®**çš„ PDDLã€‚å¦‚æœ LLM æ¼æ‰äº†ä¸€ä¸ª `(clear a)` çš„åˆå§‹çŠ¶æ€ï¼ŒSolver ä¼šç›´æ¥æŠ¥é”™æˆ–æ— è§£ã€‚
   * **è§£å†³æ€è·¯**ï¼šå¼•å…¥ **Reflexion** æœºåˆ¶ã€‚å¦‚æœ Solver æŠ¥é”™ï¼Œå°†æŠ¥é”™ä¿¡æ¯ï¼ˆå¦‚ "Syntax Error at line 5" æˆ– "Goal unreachable"ï¼‰å–‚å›ç»™ LLMï¼Œè®©å…¶ä¿®æ­£ PDDL ä»£ç ã€‚
2. **å°é—­ä¸–ç•Œå‡è®¾ (Closed World Assumption)**:

   * **å±€é™**ï¼šPDDL è¦æ±‚å…¨çŸ¥å…¨èƒ½ï¼ˆGod Viewï¼‰ã€‚ä½ å¿…é¡»å®šä¹‰æ‰€æœ‰ç‰©ä½“å’Œæ‰€æœ‰çŠ¶æ€ã€‚è¿™åœ¨ç°å®ä¸–ç•Œï¼ˆOpen Worldï¼‰ä¸­å‡ ä¹ä¸å¯èƒ½ã€‚
   * **è§£å†³æ€è·¯**ï¼š**Open-World Planning**ã€‚ç»“åˆ RAG æˆ– Vision æ¨¡å‹ï¼ŒåŠ¨æ€åœ°å‘ç°ç‰©ä½“å¹¶å¢é‡æ›´æ–° PDDL çŠ¶æ€ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§å…¨é‡å®šä¹‰ã€‚
3. **Domain ç¼–å†™æˆæœ¬**:

   * **å±€é™**ï¼šç¼–å†™ `domain.pddl` éœ€è¦ä¸“å®¶çŸ¥è¯†ï¼ˆPredicate Logicï¼‰ã€‚
   * **è§£å†³æ€è·¯**ï¼šä½¿ç”¨ LLM è¾…åŠ©ç¼–å†™ Domainï¼Œæˆ–è€…ä» API æ–‡æ¡£è‡ªåŠ¨è½¬åŒ–ä¸º Tool Domainã€‚

---

### 6. å‰æ²¿æ‰©å±•

* **LLM as PDDL Corrector**:
  ä¸è¦è®© LLM ä»é›¶å†™ PDDLã€‚è€Œæ˜¯åŸºäºä¸€ä¸ªæœ‰å™ªå£°çš„æ„ŸçŸ¥è¾“å…¥ç”Ÿæˆ PDDLï¼Œç„¶ååˆ©ç”¨ LLM çš„å¸¸è¯†æ¥**ä¿®è¡¥ï¼ˆInpaintï¼‰**ç¼ºå¤±çš„å‰ææ¡ä»¶ã€‚
* **Skill Library (Voyager Style)**:
  å°† Solver ç”Ÿæˆçš„æˆåŠŸçš„ Action Sequence å­˜å…¥å‘é‡æ•°æ®åº“ã€‚ä¸‹æ¬¡é‡åˆ°ç±»ä¼¼ä»»åŠ¡ï¼Œç›´æ¥æ£€ç´¢è¿™ä¸ª Plan ä½œä¸º Few-shotï¼Œæˆ–è€…ç›´æ¥å¤ç”¨ï¼ˆSkill Reuseï¼‰ï¼Œè·³è¿‡æ±‚è§£è¿‡ç¨‹ã€‚

---

### æ€»ç»“

LLM+P æ˜¯ä¸€ç§**ç¥ç»ç¬¦å·ä¸»ä¹‰ï¼ˆNeuro-Symbolicï¼‰**çš„å…¸å‹æ¶æ„ã€‚
å®ƒæ•™ä¼šæˆ‘ä»¬ä¸€ä¸ªæ¶æ„åŸåˆ™ï¼š**ä¸è¦è¯•å›¾è®© LLM åšå®ƒä¸æ“…é•¿çš„æœç´¢å’Œé€»è¾‘çº¦æŸé—®é¢˜ï¼Œè€Œæ˜¯è®©å®ƒå……å½“è‡ªç„¶è¯­è¨€ä¸å½¢å¼åŒ–è¯­è¨€ä¹‹é—´çš„â€œç¼–è¯‘å™¨â€ã€‚**

ä¸‹ä¸€è¯¾ï¼Œæˆ‘ä»¬å°†è¿›å…¥ **Agent å¾®è°ƒ (AgentTuning)** é¢†åŸŸï¼Œæ¢è®¨å¦‚ä½•é€šè¿‡è®­ç»ƒè®©å°æ¨¡å‹ä¹Ÿèƒ½å…·å¤‡å¼ºå¤§çš„è§„åˆ’èƒ½åŠ›ã€‚
