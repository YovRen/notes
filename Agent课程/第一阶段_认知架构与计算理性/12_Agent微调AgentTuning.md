# ç¬¬12è¯¾ï¼šAgent å¾®è°ƒ (AgentTuning)

**å…³é”®è¯**ï¼šSFT, Loss Function, FireAct, AgentLM, Trajectory Data

---

## ç¬”è®°åŒºåŸŸ

ä½ å¥½ã€‚è¿™æ˜¯ã€ŠAI Agent æ·±åº¦æ¶æ„ä¸æ•°å­¦åŸç†ã€‹çš„ç¬¬åäºŒè¯¾ã€‚

åœ¨å‰åä¸€è¯¾ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†å„ç§å¤æ‚çš„ Agent æ¶æ„ï¼ˆReAct, ToT, MCTS, Voyagerï¼‰ã€‚è¿™äº›æ¶æ„éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„å‰æï¼š**å¿…é¡»ä½¿ç”¨æå…¶å¼ºå¤§çš„åŸºåº§æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰**ã€‚
å› ä¸ºåªæœ‰ GPT-4 çº§åˆ«çš„æ¨¡å‹æ‰èƒ½åœ¨ Zero-shot æˆ– Few-shot ä¸‹ä¸¥æ ¼éµå¾ªå¤æ‚çš„æŒ‡ä»¤æ ¼å¼ï¼ˆFormat Followingï¼‰å¹¶è¿›è¡Œæ·±åº¦çš„é€»è¾‘æ¨ç†ã€‚

**èƒŒæ™¯é©±åŠ¨**ï¼š

* **æŒ‘æˆ˜ (Challenge)**ï¼š
  1. **æˆæœ¬ä¸å»¶è¿Ÿ**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¯æ¬¡ ReAct å¾ªç¯éƒ½è°ƒç”¨ GPT-4 æ—¢æ˜‚è´µåˆç¼“æ…¢ã€‚
  2. **æ ¼å¼é²æ£’æ€§**ï¼šå¼€æºå°æ¨¡å‹ï¼ˆå¦‚ Llama-2-7B, Mistral-7Bï¼‰å¾ˆéš¾é€šè¿‡ Prompt Engineering ç¨³å®šåœ°è¾“å‡ºè§„èŒƒçš„ `Thought: ... Action: ...` åºåˆ—ï¼Œç»å¸¸è§£æå¤±è´¥ã€‚
  3. **é€šç”¨èƒ½åŠ›é€€åŒ–**ï¼šå¦‚æœç›´æ¥åœ¨ Agent æ•°æ®ä¸Šå¾®è°ƒï¼Œæ¨¡å‹å¾€å¾€ä¼šå˜æˆâ€œåç§‘ç”Ÿâ€ï¼Œä¸§å¤±é€šç”¨çš„å¯¹è¯å’ŒçŸ¥è¯†èƒ½åŠ›ï¼ˆAlignment Taxï¼‰ã€‚
* **çªç ´ç‚¹ (Breakthrough)**ï¼š**AgentTuning (å¾®è°ƒ)**ã€‚å³ **Trajectory Fine-Tuning**ã€‚
* **æ”¹è¿›æ–¹å‘**ï¼š
  ä» **Prompt Engineering (ICL)** è½¬å‘ **Supervised Fine-Tuning (SFT)**ã€‚æˆ‘ä»¬å°† GPT-4 ç”Ÿæˆçš„é«˜è´¨é‡æ¨ç†è½¨è¿¹ï¼ˆTrajectoriesï¼‰ä½œä¸ºâ€œæ•™æâ€ï¼Œè’¸é¦ï¼ˆDistillï¼‰ç»™å°æ¨¡å‹ï¼Œä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¿‡ Teacher Model çš„è¡¨ç°ã€‚

---

# ğŸ§  ç¬¬12è¯¾ï¼šAgent å¾®è°ƒ (AgentTuning)

### 1. ç†è®ºæ ¸å¿ƒï¼šè½¨è¿¹ä¼˜åŒ–ä¸æ··åˆæŸå¤±

#### 1.1 æ•°å­¦å½¢å¼åŒ–ï¼šä» Token åˆ° Trajectory

åœ¨æ ‡å‡† SFT ä¸­ï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„æ˜¯ç»™å®š Prompt $x$ ç”Ÿæˆå›ç­” $y$ çš„ä¼¼ç„¶ã€‚
åœ¨ Agent SFT ä¸­ï¼Œè®­ç»ƒæ•°æ®ä¸å†æ˜¯ç®€å•çš„ $(Q, A)$ å¯¹ï¼Œè€Œæ˜¯äº¤äº’è½¨è¿¹ $\tau$ã€‚

å®šä¹‰è½¨è¿¹ $\tau = (x, a_1, o_1, a_2, o_2, \dots, a_T)$ï¼Œå…¶ä¸­ï¼š

* $x$: ç”¨æˆ·æŒ‡ä»¤ã€‚
* $a_t$: Agent çš„è¾“å‡ºï¼ˆThought + Actionï¼‰ã€‚
* $o_t$: ç¯å¢ƒåé¦ˆï¼ˆObservationï¼‰ã€‚

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ– Agent åŠ¨ä½œçš„æ¡ä»¶æ¦‚ç‡ï¼Œ**å¿½ç•¥ç¯å¢ƒåé¦ˆçš„ Loss**ï¼ˆå› ä¸ºç¯å¢ƒåé¦ˆä¸æ˜¯æ¨¡å‹ç”Ÿæˆçš„ï¼‰ï¼š

$$
\mathcal{L}_{Agent}(\theta) = - \sum_{t=1}^T \log P_\theta(a_t | x, a_1, o_1, \dots, a_{t-1}, o_{t-1})
$$

æ³¨æ„ï¼šåœ¨è®¡ç®— Loss æ—¶ï¼Œä¼šå¯¹ $x$ å’Œæ‰€æœ‰ $o_t$ åº”ç”¨ **Loss Masking**ï¼Œåªè®¡ç®— $a_t$ éƒ¨åˆ†çš„æ¢¯åº¦ã€‚

#### 1.2 æ··åˆè®­ç»ƒç­–ç•¥ (The Agent-General Trade-off)

**Zeng et al. (AgentTuning)** å‘ç°ï¼Œå¦‚æœä»…ä½¿ç”¨ Agent è½¨è¿¹è¿›è¡Œå¾®è°ƒï¼Œæ¨¡å‹çš„é€šç”¨èƒ½åŠ›ï¼ˆGeneral Capabilityï¼Œå¦‚å¸¸è¯†é—®ç­”ã€æ‘˜è¦ï¼‰ä¼šæ˜¾è‘—ä¸‹é™ã€‚
ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¿…é¡»å¼•å…¥**æ··åˆè®­ç»ƒç›®æ ‡**ï¼š

$$
\mathcal{L}_{Total}(\theta) = \lambda \mathcal{L}_{Agent}(\theta) + (1-\lambda) \mathcal{L}_{General}(\theta)
$$

* $\mathcal{L}_{Agent}$: æ¥æºäº AgentInstruct æ•°æ®é›†ï¼ˆReAct è½¨è¿¹ï¼‰ã€‚
* $\mathcal{L}_{General}$: æ¥æºäº ShareGPT æˆ– Alpaca ç­‰é€šç”¨å¯¹è¯æ•°æ®é›†ã€‚
* $\lambda$: æ··åˆç³»æ•°ï¼Œé€šå¸¸å–å€¼åœ¨ 0.2 åˆ° 0.5 ä¹‹é—´ï¼Œä»¥å¹³è¡¡ä¸“ä¸šèƒ½åŠ›ä¸é€šç”¨åº•åº§ã€‚

---

### 2. æ¶æ„è§£å‰–ä¸å·¥ç¨‹æµæ°´çº¿

#### 2.1 è’¸é¦æµæ°´çº¿ (The Distillation Pipeline)

è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ **Teacher-Student** æ¶æ„ï¼ŒåŒ…å«å››ä¸ªé˜¶æ®µï¼š

1. **Task Construction**: æ”¶é›†å¤§é‡ Agent ä»»åŠ¡ Promptï¼ˆå¦‚ HotpotQA, AlfWorld, WebShopï¼‰ã€‚
2. **Trajectory Generation (Teacher)**: ä½¿ç”¨ GPT-4 è¿è¡Œ ReAct/CoT æ¨¡å¼ï¼Œä¸ç¯å¢ƒäº¤äº’ã€‚
3. **Trajectory Filtering**: **å…³é”®æ­¥éª¤**ã€‚åªä¿ç•™**æˆåŠŸå®Œæˆä»»åŠ¡**çš„è½¨è¿¹ã€‚å¤±è´¥çš„è½¨è¿¹ï¼ˆæ­»å¾ªç¯ã€é”™è¯¯ç­”æ¡ˆï¼‰ä¸ä»…æ— ç”¨ï¼Œç”šè‡³æœ‰å®³ã€‚
4. **Hybrid Training (Student)**: å°†æ¸…æ´—åçš„è½¨è¿¹è½¬æ¢ä¸º Chat æ ¼å¼ï¼Œæ··åˆé€šç”¨æ•°æ®ï¼Œè®­ç»ƒ Llama/Mistralã€‚

#### 2.2 ç³»ç»Ÿè®¾è®¡å›¾ (Mermaid)

```mermaid
graph TD
    subgraph "Data Generation Phase"
        Tasks[Task Prompts<br>(HotpotQA, ToolBench)] --> GPT4
        Env[Environment<br>(Python, Browser)] <--> GPT4((Teacher: GPT-4))
        GPT4 -->|Interaction| RawTraj[Raw Trajectories]
      
        RawTraj --> Filter{Success Filter}
        Filter -- Pass --> AgentData[AgentInstruct Dataset]
        Filter -- Fail --> Discard[Trash]
    end
  
    subgraph "Training Phase"
        GeneralData[General Chat Data<br>(ShareGPT)] --> Mixer
        AgentData --> Mixer{Data Mixer}
      
        Mixer -->|Interleaved Batches| Trainer[SFT Trainer]
        BaseModel((Base Model<br>Llama-3-8B)) --> Trainer
      
        Trainer --> AgentLM((AgentLM))
    end
  
    style GPT4 fill:#ff9999,stroke:#333
    style AgentLM fill:#99ff99,stroke:#333
```

#### 2.3 å·¥ç¨‹åº”ç”¨ï¼šè¾“å…¥è¾“å‡ºè¯¦è§£

**åœºæ™¯**ï¼šè®­ç»ƒä¸€ä¸ª Tool-use Agentã€‚

* **Training Input (Template)**:
  ä¸ºäº†é€‚é… Llama-3 çš„ Chat æ¨¡æ¿ï¼Œæˆ‘ä»¬éœ€è¦å°† ReAct è½¨è¿¹åºåˆ—åŒ–ã€‚

  ```text
  <|begin_of_text|><|start_header_id|>system<|end_header_id|>
  You are a helpful assistant with access to tools: [Search, Calculator]...
  <|eot_id|><|start_header_id|>user<|end_header_id|>
  Who is older, Obama or Trump?
  <|eot_id|><|start_header_id|>assistant<|end_header_id|>
  Thought: I need to find their birth years.
  Action: Search("Obama birth year")
  <|eot_id|><|start_header_id|>tool<|end_header_id|>
  Observation: August 4, 1961
  <|eot_id|><|start_header_id|>assistant<|end_header_id|>
  Thought: Now for Trump.
  Action: Search("Trump birth year")
  ...
  ```

* **Loss Masking å·¥ç¨‹å®ç°**:

  * System Prompt & User Query: **Masked (Loss=0)**
  * Assistant Thought & Action: **Unmasked (Compute Loss)**
  * Tool Observation: **Masked (Loss=0)** â€”â€” *è¿™ä¸€ç‚¹è‡³å…³é‡è¦ï¼Œæˆ‘ä»¬ä¸èƒ½è®­ç»ƒæ¨¡å‹å»é¢„æµ‹ Search ä¼šè¿”å›ä»€ä¹ˆç»“æœï¼Œé‚£æ˜¯ç¯å¢ƒçš„äº‹ã€‚æ¨¡å‹åªéœ€è¦å­¦ä¹ å¦‚ä½• Reactionã€‚*

---

### 3. Code & Engineeringï¼šå®ç° Agent SFT æ•°æ®å¤„ç†

æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åˆ©ç”¨ `transformers` å’Œ `trl` åº“å‡†å¤‡å¸¦æœ‰ Masking çš„ Agent æ•°æ®é›†ã€‚è¿™æ˜¯å¾®è°ƒæœ€æ ¸å¿ƒçš„ä»£ç é€»è¾‘ã€‚

```python
import torch
from transformers import AutoTokenizer
from typing import Dict, List

class AgentDataFormatter:
    def __init__(self, model_id="meta-llama/Meta-Llama-3-8B-Instruct"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        # ç¡®ä¿ pad token å­˜åœ¨
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

    def format_trajectory(self, trajectory: List[Dict]) -> Dict:
        """
        å°†ç»“æ„åŒ–çš„ Trajectory è½¬æ¢ä¸º Tokenized Input IDs å’Œ Labels (ç”¨äº Loss Masking)
        trajectory ç»“æ„:
        [
            {"role": "user", "content": "Query..."},
            {"role": "assistant", "content": "Thought: ... Action: ..."},
            {"role": "tool", "content": "Observation: ..."},
            {"role": "assistant", "content": "Final Answer: ..."}
        ]
        """
        # ä½¿ç”¨ Llama-3 çš„ apply_chat_template (ä¸ç›´æ¥ç”Ÿæˆ tensorï¼Œå…ˆç”Ÿæˆ text)
        # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ§åˆ¶ Loss Maskï¼Œæ‰€ä»¥ä¸èƒ½ç®€å•è°ƒç”¨ apply_chat_template ä¸€æ¬¡æ€§ç”Ÿæˆ
      
        input_ids = []
        labels = []
      
        for turn in trajectory:
            role = turn['role']
            content = turn['content']
          
            # ç¼–ç å½“å‰ turn
            # è¿™é‡Œç®€åŒ–é€»è¾‘ï¼Œå®é™…éœ€æ ¹æ®å…·ä½“ Chat Template æ‹¼æ¥ Special Tokens
            # å‡è®¾ apply_chat_template èƒ½å¤„ç†å•ä¸ª message å¹¶ä¿ç•™æ ¼å¼
            encoded = self.tokenizer.apply_chat_template(
                [turn], tokenize=True, add_generation_prompt=False
            )
          
            # å»æ‰ä¸Šä¸€ä¸ª turn ç•™ä¸‹çš„ begin_of_text ç­‰ (éœ€æ ¹æ®å…·ä½“ Tokenizer è°ƒæ•´)
            if len(input_ids) > 0:
                # æŸäº› tokenizer ä¼šåœ¨å¼€å¤´åŠ  BOSï¼Œæ‹¼æ¥æ—¶éœ€å»æ‰
                pass 

            input_ids.extend(encoded)
          
            if role == "assistant":
                # Assistant çš„è¾“å‡ºéœ€è¦è®¡ç®— Loss -> Labels = Input IDs
                labels.extend(encoded)
            else:
                # User å’Œ Tool çš„è¾“å‡ºä¸éœ€è¦è®¡ç®— Loss -> Labels = -100 (PyTorch Ignore Index)
                labels.extend([-100] * len(encoded))
              
        # Truncate / Pad to max_length
        max_length = 2048
        input_ids = input_ids[:max_length]
        labels = labels[:max_length]
      
        # Convert to Tensor
        return {
            "input_ids": torch.tensor(input_ids, dtype=torch.long),
            "labels": torch.tensor(labels, dtype=torch.long),
            "attention_mask": torch.ones(len(input_ids), dtype=torch.long)
        }

# --- æ¨¡æ‹Ÿæ•°æ®æµ ---
# formatter = AgentDataFormatter()
# raw_traj = [
#     {"role": "user", "content": "Calc 1+1"},
#     {"role": "assistant", "content": "Action: Calculator(1+1)"},
#     {"role": "tool", "content": "2"},
#     {"role": "assistant", "content": "The answer is 2"}
# ]
# processed = formatter.format_trajectory(raw_traj)
# print(processed['labels']) # å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ° -100 çš„ mask æ•ˆæœ
```

---

### 4. Paper Drivenï¼šæ ¸å¿ƒè®ºæ–‡ä¸è´¡çŒ®

1. **Chen et al. (2023)**: *FireAct: Toward Language Agent Fine-tuning*.
   * **æ ¸å¿ƒè´¡çŒ®**ï¼šç³»ç»Ÿå¯¹æ¯”äº† Prompting (CoT/ReAct) å’Œ Fine-tuningã€‚å‘ç°ä½¿ç”¨ GPT-4 ç”Ÿæˆçš„ ReAct è½¨è¿¹å¾®è°ƒ Llama-2-7Bï¼Œå…¶æ€§èƒ½è¶…è¿‡äº† Prompt Engineering ä¸‹çš„ ChatGPT (3.5)ï¼Œä¸”æ¨ç†æˆæœ¬é™ä½ 70%ã€‚
   * **ç»“è®º**ï¼š**Agent èƒ½åŠ›æ˜¯å¯ä»¥è¢«è’¸é¦çš„**ï¼Œæ ¼å¼çº¦æŸå¯ä»¥é€šè¿‡ SFT å†…åŒ–ã€‚
2. **Zeng et al. (Tsinghua, 2023)**: *AgentTuning: Enabling Generalized Agent Abilities for LLMs*.
   * **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº† **AgentLM** å’Œ **AgentInstruct** æ•°æ®é›†ã€‚
   * **å…³é”®å‘ç°**ï¼šæå‡ºäº†æ··åˆè®­ç»ƒçš„é‡è¦æ€§ã€‚å¦‚æœä¸åŠ  General Dataï¼Œæ¨¡å‹ä¼šâ€œè¿‡æ‹Ÿåˆâ€åˆ°ç‰¹å®šçš„ ReAct æ ¼å¼ï¼Œå¯¼è‡´æ— æ³•è¿›è¡Œæ­£å¸¸çš„é—²èŠã€‚
3. **Qin et al. (2023)**: *ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs*.
   * **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† **DFSDT (Depth-First Search-Based Decision Tree)** æ¥ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚
   * **åŸç†**ï¼šæ—¢ç„¶å•æ¬¡ ReAct å®¹æ˜“å¤±è´¥ï¼Œé‚£å°±ç”¨ DFS æœç´¢å‡ºä¸€å †è·¯å¾„ï¼ŒæŒ‘å‡ºæˆåŠŸçš„è·¯å¾„æ¥å¾®è°ƒæ¨¡å‹ã€‚è¿™æ˜¯ **Search-to-SFT** çš„å…¸å‹åº”ç”¨ã€‚

---

### 5. Critical Thinkingï¼šæ‰¹åˆ¤æ€§åˆ†æ

AgentTuning æå…¶æœ‰æ•ˆï¼Œä½†ä¹Ÿæ˜¯ä¸€æŠŠåŒåˆƒå‰‘ã€‚

1. **Environment Overfitting (ç¯å¢ƒè¿‡æ‹Ÿåˆ)**:
   * **å±€é™**ï¼šæ¨¡å‹è®°ä½äº† GPT-4 åœ¨ç‰¹å®šç¯å¢ƒï¼ˆå¦‚ WebShop æ¨¡æ‹Ÿå™¨ï¼‰ä¸‹çš„ç‰¹å®šæ“ä½œåºåˆ—ã€‚ä¸€æ—¦ç¯å¢ƒ UI å˜äº†ï¼Œæˆ–è€… API ç­¾åå˜äº†ï¼ŒSFT æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›è¿œä¸å¦‚ Zero-shot çš„ GPT-4ã€‚
   * **è§£å†³**ï¼šå¢åŠ è®­ç»ƒæ•°æ®çš„**ç¯å¢ƒå¤šæ ·æ€§**ï¼Œæˆ–åœ¨ SFT åå¼•å…¥ RL (DPO) æ¥å­¦ä¹ ç­–ç•¥è€Œéæ­»è®°ç¡¬èƒŒã€‚
2. **Format Strictness vs. Reasoning Flexibility**:
   * **å±€é™**ï¼šSFT åçš„æ¨¡å‹å¾€å¾€å˜æˆâ€œæ ¼å¼æœºå™¨â€ã€‚å®ƒèƒ½å®Œç¾è¾“å‡º `Action: Search(...)`ï¼Œä½†å…¶å†…éƒ¨çš„ Reasoningï¼ˆThought éƒ¨åˆ†ï¼‰å¯èƒ½é€€åŒ–ï¼Œå˜æˆæ¯«æ— é€»è¾‘çš„åºŸè¯ï¼Œåªæ˜¯ä¸ºäº†å‡‘æ ¼å¼ã€‚
   * **è§£å†³**ï¼šåœ¨ Loss è®¡ç®—ä¸­ï¼Œå¢åŠ  Thought éƒ¨åˆ†çš„æƒé‡ï¼Œæˆ–è€…ä½¿ç”¨ **Process Supervision** è¿‡æ»¤æ‰æ¨ç†é€»è¾‘é”™è¯¯çš„è®­ç»ƒæ•°æ®ã€‚
3. **Data Contamination (æ•°æ®æ±¡æŸ“)**:
   * **å±€é™**ï¼šå¾ˆå¤š AgentBenchmarkï¼ˆå¦‚ HotpotQAï¼‰çš„æµ‹è¯•é›†å¯èƒ½å·²ç»è¢«åŒ…å«åœ¨åŸºç¡€æ¨¡å‹çš„é¢„è®­ç»ƒæ•°æ®æˆ– SFT æ•°æ®ä¸­ã€‚

---

### 6. å‰æ²¿æ‰©å±•

* **DPO for Agents (Direct Preference Optimization)**:
  * SFT åªæ˜¯â€œè¡Œä¸ºå…‹éš† (Behavior Cloning)â€ã€‚
  * æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥æ”¶é›† Agent çš„ç”± GPT-4 æ‰“åˆ†çš„åå¥½æ•°æ® $(x, y_w, y_l)$ï¼Œå…¶ä¸­ $y_w$ æ˜¯æˆåŠŸå®Œæˆä»»åŠ¡çš„è½¨è¿¹ï¼Œ$y_l$ æ˜¯å¤±è´¥çš„è½¨è¿¹ã€‚
  * ä½¿ç”¨ DPO è®­ç»ƒ Agentï¼Œä½¿å…¶æ˜¾å¼åœ°å­¦ä¹ â€œä»€ä¹ˆæ˜¯ä¸è¯¥åšçš„ï¼ˆå¦‚æ­»å¾ªç¯ï¼‰â€ã€‚
* **SwiftSage Architecture**:
  * å—è¯ºè´å°”å¥–å¾—ä¸» Kahneman å¯å‘ï¼Œå°† Agent è®¾è®¡ä¸ºåŒæ¨¡ç»„ï¼š
    * **Swift (System 1)**: ä¸€ä¸ªå°å‹çš„ SFT æ¨¡å‹ï¼Œå¿«é€Ÿç”Ÿæˆ Actionã€‚
    * **Sage (System 2)**: å½“å°æ¨¡å‹ Log-prob è¾ƒä½æˆ–æŠ¥é”™æ—¶ï¼Œå›é€€åˆ° GPT-4 è¿›è¡Œæ·±åº¦è§„åˆ’ï¼Œå¹¶å°†æ–°çš„è½¨è¿¹åŠ å…¥ SFT è®­ç»ƒé›†ã€‚
  * è¿™å®ç°äº†**åœ¨çº¿çš„ä¸»åŠ¨å­¦ä¹  (Online Active Learning)**ã€‚

---

### æ€»ç»“

AgentTuning æ˜¯å°† AI Agent ä»â€œåŸå‹éªŒè¯ï¼ˆDemoï¼‰â€æ¨å‘â€œå·¥ä¸šè½åœ°ï¼ˆProductionï¼‰â€çš„å…³é”®æŠ€æœ¯ã€‚
é€šè¿‡**è’¸é¦ GPT-4 çš„è½¨è¿¹**ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ 7B/8B çš„å°æ¨¡å‹ä¸Šè·å¾—åª²ç¾å¤§æ¨¡å‹çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼ŒåŒæ—¶å¤§å¹…é™ä½å»¶è¿Ÿå’Œæˆæœ¬ã€‚

**ä½œä¸š**:

1. ä¸‹è½½ `AgentInstruct` æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ã€‚
2. ä½¿ç”¨ `Llama-Factory` æˆ– `trl`ï¼Œå°è¯•å¾®è°ƒä¸€ä¸ª Llama-3-8Bã€‚
3. æµ‹è¯•å®ƒåœ¨æ²¡æœ‰ Few-shot ç¤ºä¾‹çš„æƒ…å†µä¸‹ï¼Œæ˜¯å¦èƒ½è‡ªåŠ¨éµå¾ª ReAct æ ¼å¼ã€‚

è‡³æ­¤ï¼Œæˆ‘ä»¬çš„**æ¶æ„ä¸å·¥ç¨‹ç¯‡**ï¼ˆä» CoT åˆ° Fine-tuningï¼‰å‘Šä¸€æ®µè½ã€‚ä¸‹ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬å°†æ·±å…¥**å¤šæ¨¡æ€ä¸æœªæ¥æ¶æ„**ã€‚

<style>#mermaid-1768998852610{font-family:sans-serif;font-size:16px;fill:#333;}#mermaid-1768998852610 .error-icon{fill:#552222;}#mermaid-1768998852610 .error-text{fill:#552222;stroke:#552222;}#mermaid-1768998852610 .edge-thickness-normal{stroke-width:2px;}#mermaid-1768998852610 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1768998852610 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1768998852610 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1768998852610 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1768998852610 .marker{fill:#333333;}#mermaid-1768998852610 .marker.cross{stroke:#333333;}#mermaid-1768998852610 svg{font-family:sans-serif;font-size:16px;}#mermaid-1768998852610 .label{font-family:sans-serif;color:#333;}#mermaid-1768998852610 .label text{fill:#333;}#mermaid-1768998852610 .node rect,#mermaid-1768998852610 .node circle,#mermaid-1768998852610 .node ellipse,#mermaid-1768998852610 .node polygon,#mermaid-1768998852610 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-1768998852610 .node .label{text-align:center;}#mermaid-1768998852610 .node.clickable{cursor:pointer;}#mermaid-1768998852610 .arrowheadPath{fill:#333333;}#mermaid-1768998852610 .edgePath .path{stroke:#333333;stroke-width:1.5px;}#mermaid-1768998852610 .flowchart-link{stroke:#333333;fill:none;}#mermaid-1768998852610 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-1768998852610 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-1768998852610 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-1768998852610 .cluster text{fill:#333;}#mermaid-1768998852610 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80,100%,96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-1768998852610:root{--mermaid-font-family:sans-serif;}#mermaid-1768998852610:root{--mermaid-alt-font-family:sans-serif;}#mermaid-1768998852610 flowchart{fill:apa;}</style>
