# ç¬¬01è¯¾ï¼šè®¤çŸ¥æ¶æ„æ€»è®ºä¸ System 2

**å…³é”®è¯**ï¼šSystem 1/2, Perception-Action Loop, AutoGPT, BabyAGI, ç†µå‡åˆ†æ

---

## ç¬”è®°åŒºåŸŸ

ä½ å¥½ã€‚è¿™æ˜¯ã€ŠAI Agent æ·±åº¦æ¶æ„ä¸æ•°å­¦åŸç†ã€‹çš„ç¬¬ä¸€è¯¾ã€‚

ä½œä¸ºç ”ä¸‰å­¦ç”Ÿï¼Œä½ åº”è¯¥å·²ç»éå¸¸ç†Ÿæ‚‰ Transformer çš„ `Forward Pass` æ˜¯å¦‚ä½•è®¡ç®— Next Token Probability çš„ã€‚ç„¶è€Œï¼Œå•çº¯çš„ LLM åªæ˜¯ä¸€ä¸ªâ€œæ¦‚ç‡ç»Ÿè®¡æ¨¡å‹â€ï¼Œå®ƒæ²¡æœ‰æ„å›¾ï¼ˆIntentï¼‰ï¼Œæ²¡æœ‰è®°å¿†ï¼ˆMemoryï¼‰ï¼Œä¹Ÿæ²¡æœ‰å¯¹ä¸–ç•Œçš„åŠ¨æ€æ„ŸçŸ¥ã€‚

æœ¬èŠ‚è¯¾æˆ‘ä»¬å°†ä»**è®¤çŸ¥ç§‘å­¦**ä¸**æ§åˆ¶ç†è®º**çš„äº¤å‰è§†è§’ï¼Œè§£æ„å¦‚ä½•å°†ä¸€ä¸ªé™æ€çš„ LLM å°è£…æˆä¸€ä¸ªåŠ¨æ€çš„ã€å…·å¤‡ System 2ï¼ˆæ…¢æ€è€ƒï¼‰èƒ½åŠ›çš„æ™ºèƒ½ä½“ã€‚

---

# ğŸ§  ç¬¬01è¯¾ï¼šè®¤çŸ¥æ¶æ„æ€»è®ºä¸ System 2

### 0. èƒŒæ™¯é©±åŠ¨ï¼šä»å‰é¦ˆç½‘ç»œåˆ°å¾ªç¯ç³»ç»Ÿ

* **æŒ‘æˆ˜ (Challenge)**ï¼š
  LLM æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå‡½æ•° $P(y|x)$ã€‚åœ¨æ ‡å‡†æ¨ç†ï¼ˆZero-shotï¼‰ä¸­ï¼Œå®ƒçš„è®¡ç®—æ·±åº¦ï¼ˆComputational Depthï¼‰æ˜¯å›ºå®šçš„ï¼ˆç”±å±‚æ•°å†³å®šï¼‰ã€‚
  **æ ¸å¿ƒé—®é¢˜**ï¼šå¯¹äºå¤æ‚ä»»åŠ¡ï¼ˆå¦‚â€œå†™ä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆâ€ï¼‰ï¼Œå•çº¯çš„ Next Token Prediction æ— æ³•è¿›è¡Œé•¿ç¨‹è§„åˆ’ï¼ˆLong-term Planningï¼‰ï¼Œä¸”ä¸€æ—¦ä¸­é—´æ­¥éª¤å‡ºé”™ï¼Œæ¨¡å‹æ— æ³•è‡ªæˆ‘çº æ­£ï¼ˆError Correctionï¼‰ï¼Œå› ä¸ºå®ƒæ˜¯å•å‘çš„ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰è®¡ç®—ã€‚
* **çªç ´ç‚¹ (Breakthrough)**ï¼š
  **è®¤çŸ¥æ¶æ„ï¼ˆCognitive Architectureï¼‰**ã€‚ä¸ä»…ä»…å°† LLM è§†ä¸ºæ¨¡å‹ï¼Œè€Œæ˜¯å°†å…¶è§†ä¸º CPUã€‚é€šè¿‡**é€’å½’ï¼ˆRecursionï¼‰**å’Œ**å¤–éƒ¨è®°å¿†ï¼ˆExternal Memoryï¼‰**ï¼Œå°†å•æ¬¡çš„æ¨ç†è½¬åŒ–ä¸ºä¸€ä¸ª**é¡ºåºå†³ç­–è¿‡ç¨‹ï¼ˆSequential Decision Processï¼‰**ã€‚
* **æ”¹è¿›æ–¹å‘**ï¼š
  ä» **System 1 (Fast, Intuitive, Unconscious)** è½¬å‘ **System 2 (Slow, Deliberate, Logical)**ã€‚

  * *System 1*: `Input -> LLM -> Output` (ChatGPT default behavior)
  * *System 2*: `Input -> [Thought -> Action -> Observation]^N -> Output` (Agentic behavior)

---

### 1. ç†è®ºæ ¸å¿ƒï¼šPOMDP ä¸ è®¤çŸ¥å¾ªç¯

#### 1.1 å½¢å¼åŒ–å®šä¹‰ï¼šAgent as a Policy

åœ¨æ•°å­¦ä¸Šï¼Œæˆ‘ä»¬å°† Agent å»ºæ¨¡ä¸ºè¿è¡Œåœ¨ **éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (POMDP)** ä¸­çš„ç­–ç•¥å‡½æ•°ã€‚

å®šä¹‰å…ƒç»„ $\mathcal{M} = \langle S, A, T, R, \Omega, O, \gamma \rangle$ï¼š

* $S$: ç¯å¢ƒçš„çœŸå®çŠ¶æ€ï¼ˆLatent World Stateï¼‰ï¼ŒAgent æ— æ³•å…¨çŸ¥ã€‚
* $A$: åŠ¨ä½œç©ºé—´ï¼ˆåŒ…å« Text Generation å’Œ Tool Useï¼‰ã€‚
* $\Omega$: è§‚æµ‹ç©ºé—´ï¼ˆContext Window ä¸­çš„å†…å®¹ï¼‰ã€‚
* $T$: çŠ¶æ€è½¬ç§» $P(s'|s,a)$ã€‚
* $O$: è§‚æµ‹æ¦‚ç‡ $P(o|s',a)$ã€‚

**System 2 çš„æœ¬è´¨**æ˜¯å¼•å…¥äº†**å†…éƒ¨çŠ¶æ€ï¼ˆInternal Stateï¼‰**æˆ–**è®°å¿†ï¼ˆMemoryï¼‰** $h_t$ã€‚
Agent çš„ç­–ç•¥ $\pi_\theta$ ä¸å†ä»…ä»…ä¾èµ–å½“å‰è§‚æµ‹ $o_t$ï¼Œè€Œæ˜¯ä¾èµ–å†å²è½¨è¿¹ $\tau_t$ï¼š

$$
\tau_t = (o_0, a_0, o_1, a_1, \dots, o_t)
$$

$$
a_t \sim \pi_\theta(a_t | \tau_t)
$$

#### 1.2 æ„ŸçŸ¥-è¡ŒåŠ¨å¾ªç¯ (Perception-Action Loop)

Lilian Weng åœ¨å…¶ç»å…¸åšæ–‡ä¸­æå‡ºçš„æ¶æ„ï¼Œæœ¬è´¨ä¸Šæ˜¯å¯¹äººç±»è®¤çŸ¥å¾ªç¯ï¼ˆOODA Loop: Observe-Orient-Decide-Actï¼‰çš„å·¥ç¨‹æ˜ å°„ï¼š

1. **Perception (æ„ŸçŸ¥)**: å°†ç¯å¢ƒåé¦ˆ $o_t$ ç¼–ç è¿› Contextã€‚
2. **Memory (è®°å¿†)**:
   * *Short-term*: Context Windowã€‚
   * *Long-term*: Vector Database (RAG)ã€‚
3. **Planning (è§„åˆ’ - System 2 çš„æ ¸å¿ƒ)**:
   * *Decomposition*: $Goal \to \{Subgoal_1, Subgoal_2\}$.
   * *Reflection*: æ£€æŸ¥ $a_{t-1}$ æ˜¯å¦å¯¼è‡´äº†é¢„æœŸçš„ç»“æœã€‚
4. **Action (è¡ŒåŠ¨)**: æ‰§è¡Œ API è°ƒç”¨æˆ–æ–‡æœ¬è¾“å‡ºã€‚

---

### 2. æ¶æ„è§£å‰–ï¼šReAct ä¸ è®¤çŸ¥æ•°æ®æµ

æˆ‘ä»¬ä»¥æœ€ç»å…¸çš„ **ReAct (Reasoning + Acting)** æ¶æ„ä¸ºä¾‹ï¼Œè¿™æ˜¯å®ç° System 2 çš„åŸºçŸ³ã€‚

#### 2.1 ç³»ç»Ÿè®¾è®¡å›¾ (Mermaid)

```mermaid
graph TD
    User[ç”¨æˆ·è¾“å…¥ Task] --> Memory[çŸ­æœŸè®°å¿†/Context]
    Memory --> LLM[LLM å¤§è„‘]
  
    subgraph System_2_Loop [System 2 Loop]
        direction TB
        LLM1[LLM] -->|Generate| Thought[æ€ç»´/è§„åˆ’ Thought]
        Thought -->|Decision| Action[åŠ¨ä½œ Action]
        Action -->|Execute| Tools[å¤–éƒ¨å·¥å…·/ç¯å¢ƒ]
        Tools -->|Output| Obs[è§‚æµ‹ Observation]
        Obs -->|Update| Memory1[Memory]
    end
  
    Action -->|Finish| Final[æœ€ç»ˆç­”æ¡ˆ]
  
    %% æ ·å¼å®šä¹‰å»ºè®®æ”¾åœ¨æœ€åï¼Œä¸”ç¡®ä¿ ID åŒ¹é…
    style LLM fill:#ff9,stroke:#333,stroke-width:2px
    style System_2_Loop fill:#e1f5fe,stroke:#333,stroke-dasharray: 5 5
```

#### 2.2 æ•°æ®æµè§£æ

åœ¨ ReAct æ¨¡å¼ä¸­ï¼ŒPrompt ä¸å†æ˜¯ä¸€ä¸ªç®€å•çš„ Questionï¼Œè€Œæ˜¯ä¸€ä¸ªåŠ¨æ€å¢é•¿çš„**è½¨è¿¹ï¼ˆTrajectoryï¼‰**ã€‚

* **è¾“å…¥ $x$**: "åˆ†æ AAPL è‚¡ä»·å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ã€‚"
* **Step 1**:
  * Context: `Question: x`
  * LLM Output: `Thought: éœ€è¦è·å–å®æ—¶æ•°æ®ã€‚ Action: Search("AAPL stock price")`
* **Step 2** (Environment Execution):
  * Context Update: `Question: x... Action: Search... Observation: 185.3 USD...`
  * LLM Output: `Thought: ä»·æ ¼å¤„äºé«˜ä½ï¼Œéœ€è¦çœ‹ P/E ratioã€‚ Action: Search("AAPL PE ratio")`
* **Step N**:
  * ...
  * LLM Output: `Thought: ä¿¡æ¯è¶³å¤Ÿã€‚ Final Answer: å»ºè®®æŒæœ‰...`

---

### 3. Paper Drivenï¼šæ ¸å¿ƒè®ºæ–‡ä¸è´¡çŒ®

#### 3.1 ReAct: Synergizing Reasoning and Acting in Language Models (ICLR 2023)

* **æ ¸å¿ƒè´¡çŒ®**: è§£å†³äº† CoT (Chain-of-Thought) çš„å¹»è§‰é—®é¢˜å’Œå•çº¯ Action çš„æ— è„‘æ‰§è¡Œé—®é¢˜ã€‚
* **æ–¹æ³•è®º**: å¼ºåˆ¶æ¨¡å‹åœ¨æ‰§è¡Œ Action ä¹‹å‰ç”Ÿæˆ Thoughtã€‚
  * åªæœ‰ Thought (CoT): å®¹æ˜“äº§ç”Ÿäº‹å®å¹»è§‰ï¼Œæ— æ³•è·å–å¤–éƒ¨æ–°çŸ¥ã€‚
  * åªæœ‰ Action: ç¼ºä¹æ¨ç†ï¼Œéš¾ä»¥å¤„ç†å¤šæ­¥ä¾èµ–ä»»åŠ¡ã€‚
  * **ReAct**: Thought $\leftrightarrow$ Action çš„äº¤é”™ã€‚

#### 3.2 Reflexion: Language Agents with Verbal Reinforcement Learning (NeurIPS 2023)

* **æŒ‘æˆ˜**: ReAct å¦‚æœç¬¬ä¸€æ­¥èµ°é”™äº†ï¼Œå®¹æ˜“é™·å…¥æ­»å¾ªç¯æˆ–é”™è¯¯ç´¯ç§¯ã€‚
* **æ ¸å¿ƒè´¡çŒ®**: å¼•å…¥ **Evaluator** å’Œ **Self-Reflection**ã€‚
* **æœºåˆ¶**:
  Agent äº§ç”Ÿè½¨è¿¹ $\tau$ -> Evaluator è¯„åˆ† $r$ -> å¦‚æœå¤±è´¥ï¼ŒLLM ç”Ÿæˆä¸€æ®µâ€œåæ€â€ (Self-Reflection) å­˜å…¥ Memory -> ä¸‹ä¸€æ¬¡å°è¯•æ—¶ï¼Œå°†åæ€ä½œä¸º Context è¾“å…¥ï¼Œé¿å…é‡è¹ˆè¦†è¾™ã€‚
  è¿™æœ¬è´¨ä¸Šæ˜¯ **In-context Reinforcement Learning**ã€‚

---

### 4. Code & Engineeringï¼šæ„å»ºä¸€ä¸ªæœ€å°åŒ–çš„ System 2 Agent

æˆ‘ä»¬ä¸ä½¿ç”¨ LangChainï¼Œè€Œæ˜¯ç”¨åŸç”Ÿ Python å®ç°ä¸€ä¸ªå…·å¤‡ **Loop** å’Œ **Stop Condition** çš„ Agentï¼Œä»¥ç†è§£å…¶æ§åˆ¶æµã€‚

```python
import openai
import re

class System2Agent:
    def __init__(self, system_prompt, tools):
        self.system_prompt = system_prompt
        self.tools = tools # Dict of functions
        self.history = []  # Short-term memory (Context)
        self.max_steps = 10

    def run(self, user_query):
        # åˆå§‹åŒ–çŠ¶æ€
        self.history = [{"role": "system", "content": self.system_prompt}]
        self.history.append({"role": "user", "content": user_query})
      
        step = 0
        while step < self.max_steps:
            print(f"--- Step {step} ---")
          
            # 1. Perception & Planning (LLM Inference)
            response = self._call_llm()
            print(f"Agent: {response}")
            self.history.append({"role": "assistant", "content": response})
          
            # 2. Action Parsing
            # å‡è®¾ ReAct æ ¼å¼: "Thought: ... Action: tool_name(args)"
            thought, action_name, action_args = self._parse_output(response)
          
            # 3. Stop Condition
            if action_name == "Final Answer":
                return action_args
          
            # 4. Execution (Interacting with Environment)
            observation = self._execute_tool(action_name, action_args)
            print(f"Env: {observation}")
          
            # 5. Observation Feedback (Updating Memory)
            obs_message = f"Observation: {observation}"
            self.history.append({"role": "user", "content": obs_message})
          
            step += 1
          
        return "Task failed: Max steps reached."

    def _call_llm(self):
        # å®é™…å·¥ç¨‹ä¸­è¿™é‡Œéœ€è¦å¤„ç† Retry, Timeout, Context Limit
        completion = openai.chat.completions.create(
            model="gpt-4",
            messages=self.history,
            stop=["Observation:"] # å…³é”®ï¼šé˜²æ­¢æ¨¡å‹è‡ªé—®è‡ªç­”ï¼Œç”Ÿæˆå¹»è§‰è§‚æµ‹
        )
        return completion.choices[0].message.content

    def _parse_output(self, text):
        # ç®€å•çš„æ­£åˆ™è§£æ
        action_match = re.search(r"Action:\s*(\w+)\((.*)\)", text)
        if "Final Answer:" in text:
            return None, "Final Answer", text.split("Final Answer:")[1].strip()
        if action_match:
            return None, action_match.group(1), action_match.group(2)
        return None, "None", "No action found"

    def _execute_tool(self, name, args):
        if name in self.tools:
            try:
                return self.tools[name](args)
            except Exception as e:
                return f"Error: {str(e)}"
        return "Error: Tool not found."

# --- Usage Example ---
def search_tool(query):
    return "AAPL price is 150 USD."

tools = {"search": search_tool}
prompt = """
Answer the following questions as best you can. You have access to the following tools:
search(query): useful for when you need to answer questions about current events.

Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [search]
Observation: the result of the action
... (this Thought/Action/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question
"""

agent = System2Agent(prompt, tools)
result = agent.run("What is AAPL price?")
print(f"Result: {result}")
```

### 5. å·¥ç¨‹åº”ç”¨ï¼šè¾“å…¥è¾“å‡ºä¸æ“ä½œæµ

**åœºæ™¯**ï¼šä¼ä¸šçº§æ•°æ®åˆ†æ Agentã€‚

1. **Input (ç»™å¤§æ¨¡å‹è¾“å…¥ä»€ä¹ˆ)**:

   * `System Prompt`: å®šä¹‰äººè®¾ã€å·¥å…·Schemaï¼ˆå¦‚ SQLæ‰§è¡Œå™¨ï¼‰ã€å®‰å…¨é™åˆ¶ï¼ˆåªè¯»æƒé™ï¼‰ã€‚
   * `Trajectory`: å†å²å¯¹è¯ + å½“å‰çš„ "Observation"ï¼ˆå¦‚æ•°æ®åº“è¿”å›çš„ Schema æˆ– é”™è¯¯ä¿¡æ¯ï¼‰ã€‚
   * *Prompt Engineering Tip*: åœ¨ System Prompt ä¸­åŠ å…¥ "Few-shot Examples"ï¼ˆç¤ºä¾‹ï¼‰ï¼Œå±•ç¤ºæ­£ç¡®çš„ ReAct æ ¼å¼ï¼Œè¿™å¯¹æ¨¡å‹éµå¾ªæŒ‡ä»¤è‡³å…³é‡è¦ã€‚
2. **Output (æ¨¡å‹è¾“å‡ºä»€ä¹ˆ)**:

   * ä¸€æ®µæ–‡æœ¬ï¼ŒåŒ…å«è‡ªç„¶è¯­è¨€çš„æ€è€ƒ (`Thought`) å’Œç»“æ„åŒ–çš„æŒ‡ä»¤ (`Action`).
   * ä¾‹å¦‚ï¼š`Thought: I need to query the sales table. Action: execute_sql("SELECT * FROM sales LIMIT 5")`
3. **åç»­æ“ä½œ (Processing)**:

   * **Parser**: æå– `execute_sql` å’Œ SQL è¯­å¥ã€‚
   * **Validator**: **å…³é”®æ­¥éª¤**ã€‚æ£€æŸ¥ SQL æ˜¯å¦æœ‰æ³¨å…¥é£é™©ï¼Ÿæ˜¯å¦ç¬¦åˆè¯­æ³•ï¼Ÿ
   * **Executor**: åœ¨æ²™ç®±ç¯å¢ƒä¸­æ‰§è¡Œ SQLã€‚
   * **Feedback**: å°†ç»“æœï¼ˆå¦‚ dataframe çš„ markdown å½¢å¼æˆ– error messageï¼‰æˆªæ–­ï¼ˆé˜²æ­¢çˆ† Contextï¼‰åæ‹¼æ¥åˆ° Prompt ä¸­ã€‚
4. **æœ€ç»ˆç»“æœ**:

   * Agent ç»è¿‡å¤šæ¬¡å¾ªç¯ï¼Œæœ€ç»ˆè¾“å‡º `Final Answer: Based on the data, the sales increased by 20%...`ã€‚

---

### 6. Critical Thinkingï¼šæ‰¹åˆ¤æ€§åˆ†æ

ä½œä¸ºæ¶æ„å¸ˆï¼Œå¿…é¡»çœ‹åˆ° System 2 çš„ä»£ä»·ï¼š

1. **Latency (å»¶è¿Ÿ)**:

   * ReAct æ˜¯ä¸²è¡Œçš„ã€‚å¦‚æœè§£å†³ä¸€ä¸ªé—®é¢˜éœ€è¦ 5 æ­¥ï¼Œæ„å‘³ç€ 5 æ¬¡ LLM Round-tripã€‚å¯¹äºå®æ—¶äº¤äº’åº”ç”¨ï¼Œè¿™é€šå¸¸æ˜¯ä¸å¯æ¥å—çš„ï¼ˆUser Experience Issueï¼‰ã€‚
   * *è§£å†³æ€è·¯*: **Parallel Execution** (å¦‚ä½¿ç”¨ DAG è§„åˆ’è€Œéçº¿æ€§é“¾) æˆ– **Speculative Decoding**ã€‚
2. **Cost (æˆæœ¬)**:

   * Input Context éšç€ Step å¢åŠ å‘ˆçº¿æ€§å¢é•¿ã€‚Step 10 çš„æ—¶å€™ï¼Œä½ å¯èƒ½åœ¨é‡å¤è¾“å…¥ Step 1-9 çš„æ‰€æœ‰ Tokenã€‚è¿™ä¼šå¯¼è‡´ API æˆæœ¬æŒ‡æ•°çº§ä¸Šå‡ã€‚
   * *è§£å†³æ€è·¯*: **Memory Summarization** (æ¯éš”å‡ æ­¥æ€»ç»“å†å²) æˆ– **Infinite Context** æŠ€æœ¯ã€‚
3. **Context Window & Lost in the Middle**:

   * å½“è½¨è¿¹è¿‡é•¿ï¼Œæ¨¡å‹å®¹æ˜“å¿˜è®°æœ€åˆçš„ Goal æˆ–ä¸­é—´çš„çº¦æŸã€‚
   * *è§£å†³æ€è·¯*: å¼•å…¥ç‹¬ç«‹çš„ **Planner Agent** ç»´æŠ¤é«˜å±‚ç›®æ ‡ï¼ŒWorker Agent åªå…³æ³¨å½“å‰ Stepã€‚
4. **Loop Stability (æ­»å¾ªç¯)**:

   * æ¨¡å‹å¯èƒ½ä¼šé™·å…¥ `Search -> Error -> Search -> Error` çš„æ­»å¾ªç¯ã€‚
   * *è§£å†³æ€è·¯*: å·¥ç¨‹ä¸Šå¿…é¡»è®¾ç½® `max_retries` å’Œæ£€æµ‹é‡å¤ Action çš„ Heuristic è§„åˆ™ã€‚

---

### 7. å‰æ²¿æ‰©å±•

* **System 2 + Knowledge Graph**:
  å•çº¯çš„ ReAct ä¾èµ– LLM å†…éƒ¨å‚æ•°çŸ¥è¯†ã€‚ç»“åˆ KGï¼ŒAgent å¯ä»¥åœ¨ Graph ä¸Šè¿›è¡Œå¤šè·³æ¨ç†ï¼ˆMulti-hop Reasoningï¼‰ï¼Œæ¯ä¸€æ­¥ Action å˜æˆåœ¨ KG ä¸Šæ¸¸èµ°ï¼ˆWalkï¼‰ã€‚
* **Multimodal Agents (Vision)**:
  è§‚æµ‹ç©ºé—´ $\Omega$ æ‰©å±•ä¸ºå›¾åƒã€‚ä¾‹å¦‚ **AppAgent**ï¼Œå®ƒçš„ Observation æ˜¯æ‰‹æœºå±å¹•æˆªå›¾ï¼ŒAction æ˜¯ (x,y) ç‚¹å‡»åæ ‡ã€‚æ¶æ„é€»è¾‘ä¸å˜ï¼Œä½† Encoder å˜æˆäº† Vision Transformerã€‚

---

è¿™å°±æ˜¯ç¬¬ä¸€è¯¾çš„æ ¸å¿ƒå†…å®¹ã€‚æˆ‘ä»¬å»ºç«‹äº† Agent çš„éª¨æ¶ï¼š**é€šè¿‡å¾ªç¯å’Œè®°å¿†ï¼Œå°†æ— çŠ¶æ€çš„ LLM å˜æˆäº†æœ‰çŠ¶æ€çš„ System 2 æ¨ç†æœº**ã€‚

ä¸‹ä¸€è¯¾ï¼Œæˆ‘ä»¬å°†æ·±å…¥è§£å‰– Agent çš„â€œå››è‚¢â€â€”â€”**å·¥å…·ä½¿ç”¨ä¸è§„åˆ’ç®—æ³•**ï¼Œæ¢è®¨å¦‚ä½•è®© LLM ç²¾ç¡®æ§åˆ¶å¤–éƒ¨ä¸–ç•Œã€‚

<style>#mermaid-1768967404020{font-family:sans-serif;font-size:16px;fill:#333;}#mermaid-1768967404020 .error-icon{fill:#552222;}#mermaid-1768967404020 .error-text{fill:#552222;stroke:#552222;}#mermaid-1768967404020 .edge-thickness-normal{stroke-width:2px;}#mermaid-1768967404020 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1768967404020 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1768967404020 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1768967404020 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1768967404020 .marker{fill:#333333;}#mermaid-1768967404020 .marker.cross{stroke:#333333;}#mermaid-1768967404020 svg{font-family:sans-serif;font-size:16px;}#mermaid-1768967404020 .label{font-family:sans-serif;color:#333;}#mermaid-1768967404020 .label text{fill:#333;}#mermaid-1768967404020 .node rect,#mermaid-1768967404020 .node circle,#mermaid-1768967404020 .node ellipse,#mermaid-1768967404020 .node polygon,#mermaid-1768967404020 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-1768967404020 .node .label{text-align:center;}#mermaid-1768967404020 .node.clickable{cursor:pointer;}#mermaid-1768967404020 .arrowheadPath{fill:#333333;}#mermaid-1768967404020 .edgePath .path{stroke:#333333;stroke-width:1.5px;}#mermaid-1768967404020 .flowchart-link{stroke:#333333;fill:none;}#mermaid-1768967404020 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-1768967404020 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-1768967404020 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-1768967404020 .cluster text{fill:#333;}#mermaid-1768967404020 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80,100%,96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-1768967404020:root{--mermaid-font-family:sans-serif;}#mermaid-1768967404020:root{--mermaid-alt-font-family:sans-serif;}#mermaid-1768967404020 flowchart{fill:apa;}</style>
