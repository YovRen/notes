{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7de97f4",
   "metadata": {},
   "source": [
    "### **《Agent 深度进阶大纲》**\n",
    "\n",
    "#### **第一阶段：单体智能架构 (Single Agent Architecture)**\n",
    "*目标：搞懂目前最主流的基于 LLM 的 Agent 是如何“思考”和“使用工具”的。这是所有 Agent 的地基。*\n",
    "\n",
    "*   **模块 1：认知核心与推理模式 (The Brain & Reasoning)**\n",
    "    *   **核心问题**：LLM 怎么从“只会说话”变成“会办事”？\n",
    "    *   **关键概念**：\n",
    "        *   **ReAct 范式** (Reasoning + Acting)：Agent 的圣经。\n",
    "        *   **CoT** (Chain of Thought) 及其变体 (ToT, GoT)。\n",
    "        *   **Prompt Engineering for Agents**：System Prompt 的设计哲学。\n",
    "    *   *研究生视角：为什么单纯的 Next Token Prediction 能够涌现出规划能力？*\n",
    "\n",
    "*   **模块 2：记忆与工具调用 (Memory & Tool Use)**\n",
    "    *   **核心问题**：Agent 如何记住上下文？如何连接外部世界（API）？\n",
    "    *   **关键概念**：\n",
    "        *   **记忆架构**：短期记忆 (Context Window) vs 长期记忆 (Vector DB/RAG)。\n",
    "        *   **Function Calling / Tool Former**：从文本到 JSON 指令的映射。\n",
    "        *   **Planning**：任务拆解（Decomposition）与自我反思（Self-Reflection）。\n",
    "\n",
    "#### **第二阶段：群体智能与协作 (Multi-Agent Systems)**\n",
    "*目标：理解当任务复杂时，如何组织多个 Agent 像“软件公司”一样协作。*\n",
    "\n",
    "*   **模块 3：多智能体编排 (Multi-Agent Orchestration)**\n",
    "    *   **核心问题**：一个 Agent 搞不定怎么办？如何避免三个和尚没水喝？\n",
    "    *   **关键概念**：\n",
    "        *   **SOP (标准作业程序)**：将人类工作流代码化（如 MetaGPT）。\n",
    "        *   **通信机制**：Agent 之间如何对话（如 AutoGen 的对话流）。\n",
    "        *   **角色扮演 (Role-Playing)**：通过 Persona 提升特定领域能力。\n",
    "\n",
    "#### **第三阶段：迈向物理世界 (Bridging to Embodiment)**\n",
    "*目标：从纯文本 Agent 跨越到能看懂图像、能控制机器人的 Agent。这是通往李飞飞研究的必经之路。*\n",
    "\n",
    "*   **模块 4：多模态感知与具身基础 (Multimodality & VLA)**\n",
    "    *   **核心问题**：如何把“视觉信号”变成“语言特征”？\n",
    "    *   **关键概念**：\n",
    "        *   **Vision-Language Models (VLM)**：GPT-4V, LLaVA 的原理（CLIP 是基石）。\n",
    "        *   **VLA (Vision-Language-Action)**：从 Google RT-2 看如何直接输出机器人动作。\n",
    "        *   **Grounding (落地)**：如何解决幻觉，确保识别的物体在真实坐标中存在。\n",
    "\n",
    "#### **第四阶段：空间智能与世界模型 (The Feifei Li Frontier)**\n",
    "*目标：这就是你要精通的终极目标。理解 World Labs 正在做什么。*\n",
    "\n",
    "*   **模块 5：3D 世界模型与物理模拟 (Spatial Intelligence & World Models)**\n",
    "    *   **核心问题**：Agent 如何理解 3D 几何、物理规律和因果关系？\n",
    "    *   **关键概念**：\n",
    "        *   **3D 表征**：NeRF 与 3D Gaussian Splatting（Agent 的新眼睛）。\n",
    "        *   **Generative World Models**：预测“视频”还是预测“状态”？（Sora vs. JEPA）。\n",
    "        *   **Sim-to-Real**：在虚拟环境（Isaac Sim/TDW）训练出的直觉，如何迁移到现实？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e44260",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q1: 为什么一句 \"Let's think step by step\" 有魔力？\n",
    "\n",
    "不是因为模型懂礼貌，而是因为这句 Prompt 触发了模型**从“检索模式”切换到了“推理模式”**：\n",
    "\n",
    "1.  **激活了训练数据中“教科书/代码/逻辑推导”类数据的分布**（这些数据通常包含 Step-by-step 的特征）。\n",
    "2.  **强行拉长了 Inference 的计算路径**，投入了更多算力。\n",
    "3.  **利用自回归（Auto-regressive）特性**，把复杂的 $P(y|x)$ 拆解成了简单的 $\\Pi P(z_i|z_{i-1})$。\n",
    "\n",
    "这就解释通了为什么 CoT 是 Agent 能够进行“规划”的物理基础。\n",
    "\n",
    "### Q2:ReAct enables LLMs to use tools?\n",
    "ReAct 通过协同内部认知轨迹与外部信息检索，克服了独立推理的幻觉问题和独立行动的错误传播问题。\n",
    "\n",
    "### Q3:System Prompt Engineering\n",
    "System Prompt 实际上是在利用 Transformer 的 Attention 机制，将“使用工具的规则”暂时注入到模型的权重关注点中。现在的模型（如 GPT-4o）经过了 Instruction Tuning，对 JSON 格式的遵循度很高。但在早期，让模型老老实实输出 JSON 是个大难题（需要正则匹配去解析）。\n",
    "glaiveai/glaive-function-calling-v2\n",
    "Spider (Text-to-SQL)\n",
    "ToolBench"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
