# 📚 《LLM 架构师与科学家进阶》终极课程

> 🎯 **课程目标**：从数学基础到前沿架构，全面掌握大语言模型的设计、训练、优化与部署

---

## 📋 课程概览

| 阶段 | 主题 | 课时 | 难度 |
|:---:|:---|:---:|:---:|
| 🔴 | [第一阶段：深度学习基石与数学原语](./01_深度学习基石与数学原语/README.md) | 6节 | ⭐⭐ |
| 🟠 | [第二阶段：Transformer 架构微观拆解](./02_Transformer架构微观拆解/README.md) | 8节 | ⭐⭐⭐ |
| 🟡 | [第三阶段：预训练与扩增定律](./03_预训练与扩增定律/README.md) | 6节 | ⭐⭐⭐ |
| 🟢 | [第四阶段：后训练与对齐](./04_后训练与对齐/README.md) | 7节 | ⭐⭐⭐⭐ |
| 🔵 | [第五阶段：推理加速与系统优化](./05_推理加速与系统优化/README.md) | 7节 | ⭐⭐⭐⭐ |
| 🟣 | [第六阶段：前沿架构与未来](./06_前沿架构与未来/README.md) | 6节 | ⭐⭐⭐⭐⭐ |

**总计：40 课时**

---

## 🗺️ 学习路线图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          LLM 架构师成长路径                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  🔴 数学基石        🟠 Transformer       🟡 预训练                        │
│  ┌──────────┐      ┌──────────┐        ┌──────────┐                    │
│  │ 线性代数  │ ───▶ │ Attention │ ───▶  │ Scaling  │                    │
│  │ 微积分    │      │ FFN/MoE  │        │ Laws     │                    │
│  │ 概率统计  │      │ 位置编码  │        │ 分布式   │                    │
│  └──────────┘      └──────────┘        └──────────┘                    │
│        │                │                    │                          │
│        ▼                ▼                    ▼                          │
│  🟢 后训练          🔵 推理优化         🟣 前沿架构                       │
│  ┌──────────┐      ┌──────────┐        ┌──────────┐                    │
│  │ SFT/RLHF │ ◀─── │ KV Cache │ ───▶  │ Mamba    │                    │
│  │ DPO/LoRA │      │ 量化压缩  │        │ 多模态   │                    │
│  │ 模型合并  │      │ Serving  │        │ AGI     │                    │
│  └──────────┘      └──────────┘        └──────────┘                    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 📖 课程详细目录

### 🔴 第一阶段：深度学习基石与数学原语 (6节)
> *不仅是基础，更是为了读懂最新论文中的公式推导*

- [第01课：高维空间的数学直觉](./01_深度学习基石与数学原语/01_高维空间的数学直觉.md)
- [第02课：自动微分与计算图](./01_深度学习基石与数学原语/02_自动微分与计算图.md)
- [第03课：激活函数演变史](./01_深度学习基石与数学原语/03_激活函数演变史.md)
- [第04课：归一化技术详解](./01_深度学习基石与数学原语/04_归一化技术详解.md)
- [第05课：损失函数与概率分布](./01_深度学习基石与数学原语/05_损失函数与概率分布.md)
- [第06课：优化算法的深层逻辑](./01_深度学习基石与数学原语/06_优化算法的深层逻辑.md)

### 🟠 第二阶段：Transformer 架构微观拆解 (8节)
> *拆解到每一个 Tensor 的维度变化，覆盖所有主流变体*

- [第07课：Tokenization 深度解析](./02_Transformer架构微观拆解/07_Tokenization深度解析.md)
- [第08课：Embedding 与位置编码](./02_Transformer架构微观拆解/08_Embedding与位置编码.md)
- [第09课：Attention 家族 (上)](./02_Transformer架构微观拆解/09_Attention家族上.md)
- [第10课：Attention 家族 (下)](./02_Transformer架构微观拆解/10_Attention家族下.md)
- [第11课：FFN 与 MoE](./02_Transformer架构微观拆解/11_FFN与MoE.md)
- [第12课：Transformer 架构变体总览](./02_Transformer架构微观拆解/12_Transformer架构变体总览.md)
- [第13课：初始化策略](./02_Transformer架构微观拆解/13_初始化策略.md)
- [第14课：代码级模型构建](./02_Transformer架构微观拆解/14_代码级模型构建.md)

### 🟡 第三阶段：预训练与扩增定律 (6节)
> *如何训练一个基座模型 (Base Model)*

- [第15课：数据工程](./03_预训练与扩增定律/15_数据工程.md)
- [第16课：预训练目标与策略](./03_预训练与扩增定律/16_预训练目标与策略.md)
- [第17课：Scaling Laws](./03_预训练与扩增定律/17_Scaling_Laws.md)
- [第18课：混合精度训练](./03_预训练与扩增定律/18_混合精度训练.md)
- [第19课：分布式训练基础](./03_预训练与扩增定律/19_分布式训练基础.md)
- [第20课：分布式训练进阶](./03_预训练与扩增定律/20_分布式训练进阶.md)

### 🟢 第四阶段：后训练与对齐 (7节)
> *让模型从"懂续写"变成"懂指令"和"价值观"*

- [第21课：指令微调 (SFT)](./04_后训练与对齐/21_指令微调SFT.md)
- [第22课：RLHF](./04_后训练与对齐/22_RLHF.md)
- [第23课：PPO 算法数学细节](./04_后训练与对齐/23_PPO算法数学细节.md)
- [第24课：DPO 及其变体](./04_后训练与对齐/24_DPO及其变体.md)
- [第25课：PEFT](./04_后训练与对齐/25_PEFT.md)
- [第26课：长上下文微调](./04_后训练与对齐/26_长上下文微调.md)
- [第27课：模型合并](./04_后训练与对齐/27_模型合并.md)

### 🔵 第五阶段：推理加速与系统优化 (7节)
> *如何让模型跑得快、省显存*

- [第28课：KV Cache 机制全解](./05_推理加速与系统优化/28_KV_Cache机制全解.md)
- [第29课：FlashAttention](./05_推理加速与系统优化/29_FlashAttention.md)
- [第30课：PageAttention (vLLM)](./05_推理加速与系统优化/30_PageAttention.md)
- [第31课：量化技术](./05_推理加速与系统优化/31_量化技术.md)
- [第32课：推测采样](./05_推理加速与系统优化/32_推测采样.md)
- [第33课：模型蒸馏](./05_推理加速与系统优化/33_模型蒸馏.md)
- [第34课：Serving 架构](./05_推理加速与系统优化/34_Serving架构.md)

### 🟣 第六阶段：前沿架构与未来 (6节)
> *Transformer 之后的下一代架构*

- [第35课：线性 Attention](./06_前沿架构与未来/35_线性Attention.md)
- [第36课：SSM 与 Mamba](./06_前沿架构与未来/36_SSM与Mamba.md)
- [第37课：混合架构](./06_前沿架构与未来/37_混合架构.md)
- [第38课：多模态 VLM 架构](./06_前沿架构与未来/38_多模态VLM架构.md)
- [第39课：Video 与 Audio 大模型](./06_前沿架构与未来/39_Video与Audio大模型.md)
- [第40课：迈向 AGI](./06_前沿架构与未来/40_迈向AGI.md)

---

## 📝 笔记模板说明

每节课的笔记文件包含以下结构：
- **核心概念**：关键术语和定义
- **数学公式**：相关数学推导
- **代码示例**：实现代码片段
- **图解说明**：可视化理解
- **关键问题**：常见面试题和思考题
- **参考资料**：论文和扩展阅读

---

## 🔧 学习建议

1. **按顺序学习**：课程设计有递进关系
2. **动手实践**：运行代码示例加深理解
3. **阅读论文**：参考资料中的论文是精华
4. **做笔记**：在每个文件中补充自己的理解

---

## 📅 更新日志

| 日期 | 更新内容 |
|:---:|:---|
| 2026-01-19 | 初始化课程目录结构 |

---

> 💡 **提示**：点击上方链接可直接跳转到对应课程笔记
