# 第35课：线性 Attention (Linear Attention)

> 去掉 Softmax，将复杂度从 O(N²) 降为 O(N) 的数学尝试 (RWKV, Linear Transformer)

---

## 笔记内容

